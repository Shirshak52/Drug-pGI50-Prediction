{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3677823",
   "metadata": {},
   "source": [
    "# <center>**Build MLP Model**</center>  \n",
    "**Author**: Shirshak Aryal  \n",
    "**Last Updated**: 18 July 2025\n",
    "\n",
    "---\n",
    "**Purpose:** This notebook focuses on training and evaluating a Multi-Layer Perceptron (MLP) model using PyTorch for `pGI50` prediction. It covers loading pre-split data, standardizing features, converting data to PyTorch tensors, optimizing hyperparameters with Optuna, and comprehensively evaluating the final model's performance on unseen test data.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d437d79-cc48-443b-9d1e-cc5164317b54",
   "metadata": {},
   "source": [
    "## 1. Setup Notebook\n",
    "This section initializes the notebook environment by importing all necessary libraries, configuring system and PyTorch-specific settings for performance, defining the project path for module imports, and establishing global parameters and file paths."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d9736f-e9a3-4924-b83a-d57cd3f02a8a",
   "metadata": {},
   "source": [
    "### 1.1. Configure Environment\n",
    "This section optimizes CPU thread usage for general numerical libraries and configures PyTorch-specific threading for efficient parallel processing. It also sets up the project's root directory for proper module imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca2b4681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch threads: 16\n",
      "PyTorch interop threads: 16\n",
      "Project root added to sys.path: C:\\Users\\Acer\\Desktop\\Projects for Data Science\\Drug Gi50 Value Prediction\n"
     ]
    }
   ],
   "source": [
    "# Code Cell: Environment Configuration\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "# General CPU Usage Optimization\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"16\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"16\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"16\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"16\"\n",
    "\n",
    "# PyTorch-specific CPU Usage Optimization (adjust based on your system's cores)\n",
    "try:\n",
    "    torch.set_num_threads(16)\n",
    "except RuntimeError as e:\n",
    "    print(f\"Warning: Could not set torch.set_num_threads.\\n{e}\")\n",
    "\n",
    "try:\n",
    "    torch.set_num_interop_threads(16)\n",
    "except RuntimeError as e:\n",
    "    print(f\"Warning: Could not set torch.set_num_interop_threads.\\n{e}\")\n",
    "\n",
    "print(f\"PyTorch threads: {torch.get_num_threads()}\")\n",
    "print(f\"PyTorch interop threads: {torch.get_num_interop_threads()}\")\n",
    "\n",
    "\n",
    "# Configure Project Path for Module Imports (assuming 'src' folder at project root)\n",
    "current_dir = os.getcwd()\n",
    "project_root = Path(\n",
    "    current_dir\n",
    ").parent.resolve()  # Navigates up to the project root directory\n",
    "\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "print(f\"Project root added to sys.path: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920e2111",
   "metadata": {},
   "source": [
    "### 1.2. Import Libraries\n",
    "All required Python libraries for data manipulation, neural network building (PyTorch), data preprocessing, hyperparameter optimization (Optuna), model evaluation (scikit-learn metrics), and utility functions are imported here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb2c87b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tqdm.notebook found and enabled for pandas.\n"
     ]
    }
   ],
   "source": [
    "# Standard Library Imports\n",
    "from datetime import datetime\n",
    "import subprocess  # For getting Git commit ID\n",
    "\n",
    "# Core Data Science Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# PyTorch Core for Neural Networks\n",
    "import torch.nn as nn  # Neural network modules like Linear, ReLU, MSELoss\n",
    "import torch.nn.functional as F  # Functional interface for activations, e.g. F.relu\n",
    "import torch.optim as optim  # Optimization functions like Adam, AdamW, etc.\n",
    "from torch.optim import lr_scheduler  # Learning rate scheduling\n",
    "from torch.utils.data import (\n",
    "    TensorDataset,\n",
    "    DataLoader,\n",
    ")  # Feed data to the model in batches\n",
    "\n",
    "# Custom MLP Model Class\n",
    "from src.models.mlp_models import MLP\n",
    "\n",
    "# Machine Learning Utilities\n",
    "from sklearn.metrics import mean_squared_error, r2_score  # For model evaluation metrics\n",
    "from sklearn.preprocessing import StandardScaler  # For standardizing data\n",
    "\n",
    "# Optimization & Utility Libraries\n",
    "import optuna  # For hyperparameter optimization\n",
    "\n",
    "# Conditional import for progress bars (tqdm)\n",
    "tqdm_notebook_available = False  # Initialize flag\n",
    "try:\n",
    "    from tqdm.notebook import tqdm\n",
    "\n",
    "    tqdm.pandas()  # Enable tqdm for pandas apply method\n",
    "    tqdm_notebook_available = True\n",
    "    print(\"tqdm.notebook found and enabled for pandas.\")\n",
    "except ImportError:\n",
    "    print(\"tqdm.notebook not found. Install with 'pip install tqdm'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c91343e-946d-4d69-b1e1-efec438ea09e",
   "metadata": {},
   "source": [
    "### 1.3. Define Device (CPU/GPU)\n",
    "This sub-section defines the computational device (GPU if available, otherwise CPU) for PyTorch operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01abbc85-cd0b-4899-bc1c-f6eae610214e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1560b36e-9624-4ce5-9d4b-3d1aec960aba",
   "metadata": {},
   "source": [
    "### 1.4. Set Final Model Save Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd7b983a-2456-4e0e-aad0-3ee6522afada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best final MLP model will be saved in: ..\\models\\mlp\n"
     ]
    }
   ],
   "source": [
    "mlp_models_base_dir = Path(\"../models/mlp\")\n",
    "mlp_models_base_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"The best final MLP model will be saved in: {mlp_models_base_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11429021-e5ba-47f4-bf29-1265220cee2f",
   "metadata": {},
   "source": [
    "## 2. Load Data Splits\n",
    "This section loads the pre-engineered and split datasets (training, validation, and test sets for both features and target variable) that were prepared in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea93e50c-1ae2-465b-8fd2-e6bd52b9c093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading data splits from ..\\data\\splits...\n",
      "Data splits loaded successfully.\n",
      "X_train shape: (13119, 2268)\n",
      "X_val shape: (2812, 2268)\n",
      "X_test shape: (2812, 2268)\n",
      "y_train shape: (13119, 1)\n",
      "y_val shape: (2812, 1)\n",
      "y_test shape: (2812, 1)\n",
      "\n",
      "First 5 rows of X_train:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>molregno</th>\n",
       "      <th>canonical_smiles</th>\n",
       "      <th>num_activities</th>\n",
       "      <th>MaxAbsEStateIndex</th>\n",
       "      <th>MaxEStateIndex</th>\n",
       "      <th>MinAbsEStateIndex</th>\n",
       "      <th>MinEStateIndex</th>\n",
       "      <th>qed</th>\n",
       "      <th>SPS</th>\n",
       "      <th>MolWt</th>\n",
       "      <th>...</th>\n",
       "      <th>morgan_fp_2038</th>\n",
       "      <th>morgan_fp_2039</th>\n",
       "      <th>morgan_fp_2040</th>\n",
       "      <th>morgan_fp_2041</th>\n",
       "      <th>morgan_fp_2042</th>\n",
       "      <th>morgan_fp_2043</th>\n",
       "      <th>morgan_fp_2044</th>\n",
       "      <th>morgan_fp_2045</th>\n",
       "      <th>morgan_fp_2046</th>\n",
       "      <th>morgan_fp_2047</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2307646</td>\n",
       "      <td>COc1cccc2c1OCc1c-2nc2cnc3ccccc3c2c1C</td>\n",
       "      <td>6</td>\n",
       "      <td>6.033142</td>\n",
       "      <td>6.033142</td>\n",
       "      <td>0.494176</td>\n",
       "      <td>0.494176</td>\n",
       "      <td>0.476742</td>\n",
       "      <td>12.560000</td>\n",
       "      <td>328.371</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2081122</td>\n",
       "      <td>COc1cc(/C(C#N)=C/c2ccc3c(c2)OCCO3)cc(OC)c1OC</td>\n",
       "      <td>9</td>\n",
       "      <td>9.645791</td>\n",
       "      <td>9.645791</td>\n",
       "      <td>0.459195</td>\n",
       "      <td>0.459195</td>\n",
       "      <td>0.604738</td>\n",
       "      <td>12.923077</td>\n",
       "      <td>353.374</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2199496</td>\n",
       "      <td>COC(=O)[C@@H]1CCCN1Cc1ccc(-c2ncc(-c3ccc(OCC=C(...</td>\n",
       "      <td>6</td>\n",
       "      <td>11.953178</td>\n",
       "      <td>11.953178</td>\n",
       "      <td>0.169552</td>\n",
       "      <td>-0.173158</td>\n",
       "      <td>0.359463</td>\n",
       "      <td>15.909091</td>\n",
       "      <td>447.535</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2221960</td>\n",
       "      <td>O=C(/C=C/c1cccn(C/C=C/c2ccccc2Br)c1=O)NO</td>\n",
       "      <td>4</td>\n",
       "      <td>12.253458</td>\n",
       "      <td>12.253458</td>\n",
       "      <td>0.216419</td>\n",
       "      <td>-0.686457</td>\n",
       "      <td>0.479732</td>\n",
       "      <td>11.217391</td>\n",
       "      <td>375.222</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2879093</td>\n",
       "      <td>Cc1cc(C2c3c(-c4cccc5[nH]c(=O)oc45)n[nH]c3C(=O)...</td>\n",
       "      <td>2</td>\n",
       "      <td>14.128489</td>\n",
       "      <td>14.128489</td>\n",
       "      <td>0.124437</td>\n",
       "      <td>-3.116139</td>\n",
       "      <td>0.437556</td>\n",
       "      <td>16.121212</td>\n",
       "      <td>472.879</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2268 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   molregno                                   canonical_smiles  \\\n",
       "0   2307646               COc1cccc2c1OCc1c-2nc2cnc3ccccc3c2c1C   \n",
       "1   2081122       COc1cc(/C(C#N)=C/c2ccc3c(c2)OCCO3)cc(OC)c1OC   \n",
       "2   2199496  COC(=O)[C@@H]1CCCN1Cc1ccc(-c2ncc(-c3ccc(OCC=C(...   \n",
       "3   2221960           O=C(/C=C/c1cccn(C/C=C/c2ccccc2Br)c1=O)NO   \n",
       "4   2879093  Cc1cc(C2c3c(-c4cccc5[nH]c(=O)oc45)n[nH]c3C(=O)...   \n",
       "\n",
       "   num_activities  MaxAbsEStateIndex  MaxEStateIndex  MinAbsEStateIndex  \\\n",
       "0               6           6.033142        6.033142           0.494176   \n",
       "1               9           9.645791        9.645791           0.459195   \n",
       "2               6          11.953178       11.953178           0.169552   \n",
       "3               4          12.253458       12.253458           0.216419   \n",
       "4               2          14.128489       14.128489           0.124437   \n",
       "\n",
       "   MinEStateIndex       qed        SPS    MolWt  ...  morgan_fp_2038  \\\n",
       "0        0.494176  0.476742  12.560000  328.371  ...               0   \n",
       "1        0.459195  0.604738  12.923077  353.374  ...               0   \n",
       "2       -0.173158  0.359463  15.909091  447.535  ...               0   \n",
       "3       -0.686457  0.479732  11.217391  375.222  ...               0   \n",
       "4       -3.116139  0.437556  16.121212  472.879  ...               0   \n",
       "\n",
       "   morgan_fp_2039  morgan_fp_2040  morgan_fp_2041  morgan_fp_2042  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   morgan_fp_2043  morgan_fp_2044  morgan_fp_2045  morgan_fp_2046  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   morgan_fp_2047  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "\n",
       "[5 rows x 2268 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 5 rows of y_train:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pGI50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14387</th>\n",
       "      <td>5.734742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12543</th>\n",
       "      <td>7.164746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12810</th>\n",
       "      <td>4.928428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13172</th>\n",
       "      <td>6.882724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18712</th>\n",
       "      <td>6.094208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pGI50\n",
       "14387  5.734742\n",
       "12543  7.164746\n",
       "12810  4.928428\n",
       "13172  6.882724\n",
       "18712  6.094208"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "splits_dir = Path(\"../data/splits\")\n",
    "print(f\"\\nLoading data splits from {splits_dir}...\")\n",
    "\n",
    "try:\n",
    "    X_train = pd.read_parquet(splits_dir / \"X_train.parquet\")\n",
    "    X_val = pd.read_parquet(splits_dir / \"X_val.parquet\")\n",
    "    X_test = pd.read_parquet(splits_dir / \"X_test.parquet\")\n",
    "    \n",
    "    y_train = pd.read_parquet(splits_dir / \"y_train.parquet\")\n",
    "    y_val = pd.read_parquet(splits_dir / \"y_val.parquet\")\n",
    "    y_test = pd.read_parquet(splits_dir / \"y_test.parquet\")\n",
    "    print(\"Data splits loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: One or more split files not found in '{splits_dir}'.\")\n",
    "    print(\"Please ensure you have run '02_Split_Features.ipynb' to generate and save the splits.\")\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_val shape: {y_val.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "# Display first few rows to verify data\n",
    "print(\"\\nFirst 5 rows of X_train:\")\n",
    "display(X_train.head())\n",
    "\n",
    "print(\"\\nFirst 5 rows of y_train:\")\n",
    "display(y_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fdffce-3a7f-45ae-a8af-5a3adfa3fbbe",
   "metadata": {},
   "source": [
    "## 3. Prepare Data for MLP\n",
    "This section performs the necessary data preparation steps specifically for the MLP model, including dropping identifier columns, standardizing features, and converting data into PyTorch tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b34d22a",
   "metadata": {},
   "source": [
    "### 3.1. Drop Identifier Columns\n",
    "Identifier columns (i.e., `molregno` and `canonical_smiles`) are removed from the feature sets as they are not used as input for the MLP model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "720e2ec5-e2c8-42b1-b6c3-0a95f6df39d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing X for MLP training (dropping identifiers)...\n",
      "X_train_mlp shape (numerical features only): (13119, 2266)\n",
      "X_val_mlp shape (numerical features only): (2812, 2266)\n",
      "X_test_mlp shape (numerical features only): (2812, 2266)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_activities</th>\n",
       "      <th>MaxAbsEStateIndex</th>\n",
       "      <th>MaxEStateIndex</th>\n",
       "      <th>MinAbsEStateIndex</th>\n",
       "      <th>MinEStateIndex</th>\n",
       "      <th>qed</th>\n",
       "      <th>SPS</th>\n",
       "      <th>MolWt</th>\n",
       "      <th>HeavyAtomMolWt</th>\n",
       "      <th>ExactMolWt</th>\n",
       "      <th>...</th>\n",
       "      <th>morgan_fp_2038</th>\n",
       "      <th>morgan_fp_2039</th>\n",
       "      <th>morgan_fp_2040</th>\n",
       "      <th>morgan_fp_2041</th>\n",
       "      <th>morgan_fp_2042</th>\n",
       "      <th>morgan_fp_2043</th>\n",
       "      <th>morgan_fp_2044</th>\n",
       "      <th>morgan_fp_2045</th>\n",
       "      <th>morgan_fp_2046</th>\n",
       "      <th>morgan_fp_2047</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>6.033142</td>\n",
       "      <td>6.033142</td>\n",
       "      <td>0.494176</td>\n",
       "      <td>0.494176</td>\n",
       "      <td>0.476742</td>\n",
       "      <td>12.560000</td>\n",
       "      <td>328.371</td>\n",
       "      <td>312.243</td>\n",
       "      <td>328.121178</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>9.645791</td>\n",
       "      <td>9.645791</td>\n",
       "      <td>0.459195</td>\n",
       "      <td>0.459195</td>\n",
       "      <td>0.604738</td>\n",
       "      <td>12.923077</td>\n",
       "      <td>353.374</td>\n",
       "      <td>334.222</td>\n",
       "      <td>353.126323</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>11.953178</td>\n",
       "      <td>11.953178</td>\n",
       "      <td>0.169552</td>\n",
       "      <td>-0.173158</td>\n",
       "      <td>0.359463</td>\n",
       "      <td>15.909091</td>\n",
       "      <td>447.535</td>\n",
       "      <td>418.303</td>\n",
       "      <td>447.215806</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>12.253458</td>\n",
       "      <td>12.253458</td>\n",
       "      <td>0.216419</td>\n",
       "      <td>-0.686457</td>\n",
       "      <td>0.479732</td>\n",
       "      <td>11.217391</td>\n",
       "      <td>375.222</td>\n",
       "      <td>360.102</td>\n",
       "      <td>374.026604</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>14.128489</td>\n",
       "      <td>14.128489</td>\n",
       "      <td>0.124437</td>\n",
       "      <td>-3.116139</td>\n",
       "      <td>0.437556</td>\n",
       "      <td>16.121212</td>\n",
       "      <td>472.879</td>\n",
       "      <td>453.727</td>\n",
       "      <td>472.111375</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2266 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_activities  MaxAbsEStateIndex  MaxEStateIndex  MinAbsEStateIndex  \\\n",
       "0               6           6.033142        6.033142           0.494176   \n",
       "1               9           9.645791        9.645791           0.459195   \n",
       "2               6          11.953178       11.953178           0.169552   \n",
       "3               4          12.253458       12.253458           0.216419   \n",
       "4               2          14.128489       14.128489           0.124437   \n",
       "\n",
       "   MinEStateIndex       qed        SPS    MolWt  HeavyAtomMolWt  ExactMolWt  \\\n",
       "0        0.494176  0.476742  12.560000  328.371         312.243  328.121178   \n",
       "1        0.459195  0.604738  12.923077  353.374         334.222  353.126323   \n",
       "2       -0.173158  0.359463  15.909091  447.535         418.303  447.215806   \n",
       "3       -0.686457  0.479732  11.217391  375.222         360.102  374.026604   \n",
       "4       -3.116139  0.437556  16.121212  472.879         453.727  472.111375   \n",
       "\n",
       "   ...  morgan_fp_2038  morgan_fp_2039  morgan_fp_2040  morgan_fp_2041  \\\n",
       "0  ...               0               0               0               0   \n",
       "1  ...               0               0               0               0   \n",
       "2  ...               0               0               0               0   \n",
       "3  ...               0               0               0               0   \n",
       "4  ...               0               0               0               0   \n",
       "\n",
       "   morgan_fp_2042  morgan_fp_2043  morgan_fp_2044  morgan_fp_2045  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   morgan_fp_2046  morgan_fp_2047  \n",
       "0               0               0  \n",
       "1               0               0  \n",
       "2               0               0  \n",
       "3               0               0  \n",
       "4               0               0  \n",
       "\n",
       "[5 rows x 2266 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pGI50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14387</th>\n",
       "      <td>5.734742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12543</th>\n",
       "      <td>7.164746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12810</th>\n",
       "      <td>4.928428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13172</th>\n",
       "      <td>6.882724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18712</th>\n",
       "      <td>6.094208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pGI50\n",
       "14387  5.734742\n",
       "12543  7.164746\n",
       "12810  4.928428\n",
       "13172  6.882724\n",
       "18712  6.094208"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data converted to NumPy arrays.\n",
      "X_train_np shape: (13119, 2266), y_train_np shape: (13119, 1)\n",
      "X_val_np shape: (2812, 2266), y_val_np shape: (2812, 1)\n",
      "X_test_np shape: (2812, 2266), y_test_np shape: (2812, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPreparing X for MLP training (dropping identifiers)...\")\n",
    "X_train_mlp = X_train.drop(columns=['molregno', 'canonical_smiles'], errors='ignore')\n",
    "X_val_mlp = X_val.drop(columns=['molregno', 'canonical_smiles'], errors='ignore')\n",
    "X_test_mlp = X_test.drop(columns=['molregno', 'canonical_smiles'], errors='ignore')\n",
    "\n",
    "print(f\"X_train_mlp shape (numerical features only): {X_train_mlp.shape}\")\n",
    "print(f\"X_val_mlp shape (numerical features only): {X_val_mlp.shape}\")\n",
    "print(f\"X_test_mlp shape (numerical features only): {X_test_mlp.shape}\")\n",
    "\n",
    "display(X_train_mlp.head())\n",
    "display(y_train.head())\n",
    "\n",
    "X_train_np = X_train_mlp.values\n",
    "y_train_np = y_train.values.reshape(-1, 1)\n",
    "\n",
    "X_val_np = X_val_mlp.values\n",
    "y_val_np = y_val.values.reshape(-1, 1)\n",
    "\n",
    "X_test_np = X_test_mlp.values\n",
    "y_test_np = y_test.values.reshape(-1, 1)\n",
    "\n",
    "print(\"Data converted to NumPy arrays.\")\n",
    "print(f\"X_train_np shape: {X_train_np.shape}, y_train_np shape: {y_train_np.shape}\")\n",
    "print(f\"X_val_np shape: {X_val_np.shape}, y_val_np shape: {y_val_np.shape}\")\n",
    "print(f\"X_test_np shape: {X_test_np.shape}, y_test_np shape: {y_test_np.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2ec5c7-198c-4503-89a5-07b79f3948fa",
   "metadata": {},
   "source": [
    "### 3.2. Standardize Data\n",
    "Feature data is then standardized using `StandardScaler`, fitted *only on the training features* to prevent data leakage, and then *applied to all three data splits* (training, validation, and test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "402bb90e-f384-4949-b342-02075fe6453e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scaling features using StandardScaler for MLP...\n",
      "Features scaled successfully.\n",
      "X_train_scaled_np shape: (13119, 2266)\n",
      "X_val_scaled_np shape: (2812, 2266)\n",
      "X_test_scaled_np shape: (2812, 2266)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nScaling features using StandardScaler for MLP...\")\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# ONLY fit_transform on TRAINING data\n",
    "X_train_scaled_np = scaler.fit_transform(X_train_np)\n",
    "X_val_scaled_np = scaler.transform(X_val_np)\n",
    "X_test_scaled_np = scaler.transform(X_test_np)\n",
    "\n",
    "print(\"Features scaled successfully.\")\n",
    "print(f\"X_train_scaled_np shape: {X_train_scaled_np.shape}\")\n",
    "print(f\"X_val_scaled_np shape: {X_val_scaled_np.shape}\")\n",
    "print(f\"X_test_scaled_np shape: {X_test_scaled_np.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbf278e-3b42-4f9f-af1d-df0df2961421",
   "metadata": {},
   "source": [
    "### 3.3. Convert Data to PyTorch Tensors\n",
    "The processed NumPy arrays are converted into PyTorch tensors and moved to the designated computational device (GPU or CPU) for efficient training with PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e47270d-848a-4a67-bd8b-a8252b8b0ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Converting Scaled NumPy Arrays to PyTorch Tensors ---\n",
      "Data converted to PyTorch Tensors and moved to device.\n",
      "X_train_tensor device: cuda:0, shape: torch.Size([13119, 2266])\n",
      "y_train_tensor device: cuda:0, shape: torch.Size([13119, 1])\n",
      "X_val_tensor device: cuda:0, shape: torch.Size([2812, 2266])\n",
      "y_val_tensor device: cuda:0, shape: torch.Size([2812, 1])\n",
      "X_test_tensor device: cuda:0, shape: torch.Size([2812, 2266])\n",
      "y_test_tensor device: cuda:0, shape: torch.Size([2812, 1])\n"
     ]
    }
   ],
   "source": [
    "if 'device' not in locals(): # Check if device variable is already set\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Device not previously set, now using: {device}\")\n",
    "\n",
    "print(\"\\n--- Converting Scaled NumPy Arrays to PyTorch Tensors ---\")\n",
    "X_train_tensor = torch.from_numpy(X_train_scaled_np).float().to(device)\n",
    "y_train_tensor = torch.from_numpy(y_train_np).float().to(device)\n",
    "X_val_tensor = torch.from_numpy(X_val_scaled_np).float().to(device)\n",
    "y_val_tensor = torch.from_numpy(y_val_np).float().to(device)\n",
    "X_test_tensor = torch.from_numpy(X_test_scaled_np).float().to(device)\n",
    "y_test_tensor = torch.from_numpy(y_test_np).float().to(device)\n",
    "\n",
    "print(\"Data converted to PyTorch Tensors and moved to device.\")\n",
    "print(f\"X_train_tensor device: {X_train_tensor.device}, shape: {X_train_tensor.shape}\")\n",
    "print(f\"y_train_tensor device: {y_train_tensor.device}, shape: {y_train_tensor.shape}\")\n",
    "print(f\"X_val_tensor device: {X_val_tensor.device}, shape: {X_val_tensor.shape}\")\n",
    "print(f\"y_val_tensor device: {y_val_tensor.device}, shape: {y_val_tensor.shape}\")\n",
    "print(f\"X_test_tensor device: {X_test_tensor.device}, shape: {X_test_tensor.shape}\")\n",
    "print(f\"y_test_tensor device: {y_test_tensor.device}, shape: {y_test_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487e3a9c-d5f7-4357-a366-d5f5603b9244",
   "metadata": {},
   "source": [
    "## 4. Optimize Hyperparameters\n",
    "This section utilizes Optuna to systematically search for the optimal set of hyperparameters for the MLP model, aiming to minimize prediction error on the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d243231-030c-45ef-9825-f13095dfa3ce",
   "metadata": {},
   "source": [
    "### 4.1. Define Optuna Objective Function\n",
    "The Optuna objective function is defined here. This function trains an MLP model with a given set of hyperparameters and returns its performance (i.e., RMSE) on the validation set, which Optuna aims to minimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e4bff22-8189-4706-b87f-e3240469b67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Hyperparameters to tune\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 128, 1024, log=True) # Number of neurons in hidden layer\n",
    "    learning_rate = trial.suggest_float(\"lr\", 1e-4, 5e-3, log=True) # Learning rate for optimizer\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [64, 128, 256]) # Batch size for DataLoaders\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 150, 600) # Number of training epochs\n",
    "\n",
    "    # Initialize model\n",
    "    # input_size is number of features in X_train_tensor\n",
    "    input_size = X_train_tensor.shape[1]\n",
    "    output_size = 1  # For regression (pGI50)\n",
    "\n",
    "    model = MLP(input_size, hidden_size, output_size).to(device)\n",
    "\n",
    "    # Loss function and Optimizer\n",
    "    criterion = nn.MSELoss() # Mean Squared Error Loss for regression\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # DataLoaders for batching within the trial\n",
    "    # Re-create DataLoaders here because batch_size is a hyperparameter\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Early Stopping Logic\n",
    "    best_val_rmse = float('inf')\n",
    "    patience_counter = 0\n",
    "    patience = 50 # Number of epochs to wait for improvement before stopping\n",
    "\n",
    "     # Training Loop\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            optimizer.zero_grad()  # Zero the gradients before backpropagation\n",
    "            outputs = model(batch_x)  # Forward pass\n",
    "            \n",
    "            loss = criterion(outputs, batch_y)  # Calculate loss\n",
    "            loss.backward()  # Backward pass: compute gradients\n",
    "            optimizer.step() # Apply gradients\n",
    "\n",
    "        # Validation Step\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        val_predictions = []\n",
    "        val_targets = []\n",
    "        with torch.no_grad():  # Disable gradient calculations for validation\n",
    "            for batch_x_val, batch_y_val in val_loader:\n",
    "                val_outputs = model(batch_x_val)\n",
    "                val_predictions.extend(val_outputs.cpu().numpy().flatten())\n",
    "                val_targets.extend(batch_y_val.cpu().numpy().flatten())\n",
    "\n",
    "        val_rmse = np.sqrt(mean_squared_error(val_targets, val_predictions))\n",
    "\n",
    "        # Optuna Pruning: Report current validation RMSE to Optuna\n",
    "        trial.report(val_rmse, epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "        # Manual Early Stopping Check\n",
    "        if val_rmse < best_val_rmse:\n",
    "            best_val_rmse = val_rmse\n",
    "            patience_counter = 0  # Reset patience if improvement is found\n",
    "\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                # print(f\"Early stopping at epoch {epoch+1} for trial {trial.number}\")\n",
    "                break\n",
    "\n",
    "    # Final evaluation on validation set after training (or early stopping)\n",
    "    model.eval()\n",
    "    final_val_predictions = []\n",
    "    final_val_targets = []\n",
    "    with torch.no_grad():\n",
    "        for batch_x_val, batch_y_val in val_loader:\n",
    "            val_outputs = model(batch_x_val)\n",
    "            final_val_predictions.extend(val_outputs.cpu().numpy().flatten())\n",
    "            final_val_targets.extend(batch_y_val.cpu().numpy().flatten())\n",
    "\n",
    "    final_rmse = np.sqrt(mean_squared_error(final_val_targets, final_val_predictions))\n",
    "    final_r2 = r2_score(final_val_targets, final_val_predictions)\n",
    "\n",
    "    # Store R2 score as well in the study\n",
    "    trial.set_user_attr(\"final_r2_score\", float(final_r2))\n",
    "\n",
    "    return final_rmse # Optuna minimizes this value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a5a47f-acb8-4f2b-a23c-839676f6d526",
   "metadata": {},
   "source": [
    "### 4.2. Run Optuna Study\n",
    "An Optuna study is created and executed to perform the hyperparameter optimization, iterating through trials to find the best combination of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "deb4ef0e-f10d-4faf-be70-8ac605df22f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna study for MLP will be stored at: sqlite:///..\\studies\\mlp_study\\mlp_optuna_study.db\n",
      "Loaded existing study 'mlp_regression_pGI50' from sqlite:///..\\studies\\mlp_study\\mlp_optuna_study.db. Resuming optimization.\n",
      "\n",
      "Starting Optuna optimization for MLP...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1394efb1c9a5461ebeadf510bd6902ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-07-16 00:19:45,672] Trial 152 failed with parameters: {'hidden_size': 798, 'lr': 0.00015796229731260928, 'batch_size': 128, 'n_epochs': 159} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Acer\\Desktop\\Projects for Data Science\\Drug Gi50 Value Prediction\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Acer\\AppData\\Local\\Temp\\ipykernel_47116\\170544741.py\", line 17, in objective\n",
      "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Acer\\Desktop\\Projects for Data Science\\Drug Gi50 Value Prediction\\venv\\Lib\\site-packages\\torch\\optim\\adam.py\", line 100, in __init__\n",
      "    super().__init__(params, defaults)\n",
      "  File \"C:\\Users\\Acer\\Desktop\\Projects for Data Science\\Drug Gi50 Value Prediction\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py\", line 369, in __init__\n",
      "    self.add_param_group(cast(dict, param_group))\n",
      "  File \"C:\\Users\\Acer\\Desktop\\Projects for Data Science\\Drug Gi50 Value Prediction\\venv\\Lib\\site-packages\\torch\\_compile.py\", line 46, in inner\n",
      "    import torch._dynamo\n",
      "  File \"C:\\Users\\Acer\\Desktop\\Projects for Data Science\\Drug Gi50 Value Prediction\\venv\\Lib\\site-packages\\torch\\_dynamo\\__init__.py\", line 13, in <module>\n",
      "    from . import config, convert_frame, eval_frame, resume_execution\n",
      "  File \"C:\\Users\\Acer\\Desktop\\Projects for Data Science\\Drug Gi50 Value Prediction\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 52, in <module>\n",
      "    from torch._dynamo.symbolic_convert import TensorifyState\n",
      "  File \"C:\\Users\\Acer\\Desktop\\Projects for Data Science\\Drug Gi50 Value Prediction\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 52, in <module>\n",
      "    from torch._dynamo.exc import TensorifyScalarRestartAnalysis\n",
      "  File \"C:\\Users\\Acer\\Desktop\\Projects for Data Science\\Drug Gi50 Value Prediction\\venv\\Lib\\site-packages\\torch\\_dynamo\\exc.py\", line 41, in <module>\n",
      "    from .utils import counters\n",
      "  File \"C:\\Users\\Acer\\Desktop\\Projects for Data Science\\Drug Gi50 Value Prediction\\venv\\Lib\\site-packages\\torch\\_dynamo\\utils.py\", line 69, in <module>\n",
      "    import torch.fx.experimental.symbolic_shapes\n",
      "  File \"C:\\Users\\Acer\\Desktop\\Projects for Data Science\\Drug Gi50 Value Prediction\\venv\\Lib\\site-packages\\torch\\fx\\experimental\\symbolic_shapes.py\", line 67, in <module>\n",
      "    from torch.utils._sympy.functions import (\n",
      "  File \"C:\\Users\\Acer\\Desktop\\Projects for Data Science\\Drug Gi50 Value Prediction\\venv\\Lib\\site-packages\\torch\\utils\\_sympy\\functions.py\", line 9, in <module>\n",
      "    import sympy\n",
      "  File \"C:\\Users\\Acer\\Desktop\\Projects for Data Science\\Drug Gi50 Value Prediction\\venv\\Lib\\site-packages\\sympy\\__init__.py\", line 74, in <module>\n",
      "    from .polys import (Poly, PurePoly, poly_from_expr, parallel_poly_from_expr,\n",
      "  File \"C:\\Users\\Acer\\Desktop\\Projects for Data Science\\Drug Gi50 Value Prediction\\venv\\Lib\\site-packages\\sympy\\polys\\__init__.py\", line 124, in <module>\n",
      "    from .partfrac import apart, apart_list, assemble_partfrac_list\n",
      "  File \"C:\\Users\\Acer\\Desktop\\Projects for Data Science\\Drug Gi50 Value Prediction\\venv\\Lib\\site-packages\\sympy\\polys\\partfrac.py\", line 13, in <module>\n",
      "    @xthreaded\n",
      "     ^^^^^^^^^\n",
      "  File \"C:\\Users\\Acer\\Desktop\\Projects for Data Science\\Drug Gi50 Value Prediction\\venv\\Lib\\site-packages\\sympy\\utilities\\decorator.py\", line 76, in xthreaded\n",
      "    return threaded_factory(func, False)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Acer\\Desktop\\Projects for Data Science\\Drug Gi50 Value Prediction\\venv\\Lib\\site-packages\\sympy\\utilities\\decorator.py\", line 13, in threaded_factory\n",
      "    from sympy.matrices import MatrixBase\n",
      "  File \"C:\\Users\\Acer\\Desktop\\Projects for Data Science\\Drug Gi50 Value Prediction\\venv\\Lib\\site-packages\\sympy\\matrices\\__init__.py\", line 22, in <module>\n",
      "    from .immutable import ImmutableDenseMatrix, ImmutableSparseMatrix\n",
      "  File \"C:\\Users\\Acer\\Desktop\\Projects for Data Science\\Drug Gi50 Value Prediction\\venv\\Lib\\site-packages\\sympy\\matrices\\immutable.py\", line 8, in <module>\n",
      "    from sympy.matrices.expressions import MatrixExpr\n",
      "  File \"C:\\Users\\Acer\\Desktop\\Projects for Data Science\\Drug Gi50 Value Prediction\\venv\\Lib\\site-packages\\sympy\\matrices\\expressions\\__init__.py\", line 3, in <module>\n",
      "    from .slice import MatrixSlice\n",
      "  File \"C:\\Users\\Acer\\Desktop\\Projects for Data Science\\Drug Gi50 Value Prediction\\venv\\Lib\\site-packages\\sympy\\matrices\\expressions\\slice.py\", line 1, in <module>\n",
      "    from sympy.matrices.expressions.matexpr import MatrixExpr\n",
      "  File \"C:\\Users\\Acer\\Desktop\\Projects for Data Science\\Drug Gi50 Value Prediction\\venv\\Lib\\site-packages\\sympy\\matrices\\expressions\\matexpr.py\", line 882, in <module>\n",
      "    from .matmul import MatMul\n",
      "  File \"C:\\Users\\Acer\\Desktop\\Projects for Data Science\\Drug Gi50 Value Prediction\\venv\\Lib\\site-packages\\sympy\\matrices\\expressions\\matmul.py\", line 15, in <module>\n",
      "    from .inverse import Inverse\n",
      "  File \"C:\\Users\\Acer\\Desktop\\Projects for Data Science\\Drug Gi50 Value Prediction\\venv\\Lib\\site-packages\\sympy\\matrices\\expressions\\inverse.py\", line 5, in <module>\n",
      "    from sympy.matrices.expressions.matpow import MatPow\n",
      "  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1138, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 1078, in _find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1504, in find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1476, in _get_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1612, in find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 147, in _path_stat\n",
      "KeyboardInterrupt\n",
      "[W 2025-07-16 00:19:46,012] Trial 152 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     22\u001b[39m     study = optuna.create_study(\n\u001b[32m     23\u001b[39m         study_name=study_name,\n\u001b[32m     24\u001b[39m         direction=\u001b[33m\"\u001b[39m\u001b[33mminimize\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     25\u001b[39m         storage=study_db_path,\n\u001b[32m     26\u001b[39m         pruner=pruner\n\u001b[32m     27\u001b[39m     )\n\u001b[32m     29\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mStarting Optuna optimization for MLP...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m                   \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m                   \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m7200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m                   \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mOptuna optimization finished for MLP.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Print best trial results\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Projects for Data Science\\Drug Gi50 Value Prediction\\venv\\Lib\\site-packages\\optuna\\study\\study.py:489\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    388\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    389\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    396\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    397\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    398\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    399\u001b[39m \n\u001b[32m    400\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    487\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    488\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Projects for Data Science\\Drug Gi50 Value Prediction\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:64\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     77\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Projects for Data Science\\Drug Gi50 Value Prediction\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:161\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Projects for Data Science\\Drug Gi50 Value Prediction\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:253\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    246\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    249\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    250\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    251\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    252\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Projects for Data Science\\Drug Gi50 Value Prediction\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:201\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    203\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    204\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Loss function and Optimizer\u001b[39;00m\n\u001b[32m     16\u001b[39m criterion = nn.MSELoss() \u001b[38;5;66;03m# Mean Squared Error Loss for regression\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m optimizer = \u001b[43moptim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# DataLoaders for batching within the trial\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Re-create DataLoaders here because batch_size is a hyperparameter\u001b[39;00m\n\u001b[32m     21\u001b[39m train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Projects for Data Science\\Drug Gi50 Value Prediction\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:100\u001b[39m, in \u001b[36mAdam.__init__\u001b[39m\u001b[34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused, decoupled_weight_decay)\u001b[39m\n\u001b[32m     85\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mTensor betas[1] must be 1-element\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     87\u001b[39m defaults = \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m     88\u001b[39m     lr=lr,\n\u001b[32m     89\u001b[39m     betas=betas,\n\u001b[32m   (...)\u001b[39m\u001b[32m     98\u001b[39m     decoupled_weight_decay=decoupled_weight_decay,\n\u001b[32m     99\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fused:\n\u001b[32m    103\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m differentiable:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Projects for Data Science\\Drug Gi50 Value Prediction\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:369\u001b[39m, in \u001b[36mOptimizer.__init__\u001b[39m\u001b[34m(self, params, defaults)\u001b[39m\n\u001b[32m    366\u001b[39m     param_groups = [{\u001b[33m\"\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m\"\u001b[39m: param_groups}]\n\u001b[32m    368\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m param_group \u001b[38;5;129;01min\u001b[39;00m param_groups:\n\u001b[32m--> \u001b[39m\u001b[32m369\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd_param_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_group\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[38;5;66;03m# Allows _cuda_graph_capture_health_check to rig a poor man's TORCH_WARN_ONCE in python,\u001b[39;00m\n\u001b[32m    372\u001b[39m \u001b[38;5;66;03m# which I don't think exists\u001b[39;00m\n\u001b[32m    373\u001b[39m \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/issues/72948\u001b[39;00m\n\u001b[32m    374\u001b[39m \u001b[38;5;28mself\u001b[39m._warned_capturable_if_run_uncaptured = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Projects for Data Science\\Drug Gi50 Value Prediction\\venv\\Lib\\site-packages\\torch\\_compile.py:46\u001b[39m, in \u001b[36m_disable_dynamo.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     44\u001b[39m disable_fn = \u001b[38;5;28mgetattr\u001b[39m(fn, \u001b[33m\"\u001b[39m\u001b[33m__dynamo_disable\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m disable_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\n\u001b[32m     48\u001b[39m     disable_fn = torch._dynamo.disable(fn, recursive)\n\u001b[32m     49\u001b[39m     fn.__dynamo_disable = disable_fn  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Projects for Data Science\\Drug Gi50 Value Prediction\\venv\\Lib\\site-packages\\torch\\_dynamo\\__init__.py:13\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mTorchDynamo is a Python-level JIT compiler designed to make unmodified PyTorch programs faster.\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mTorchDynamo hooks into the frame evaluation API in CPython (PEP 523) to dynamically modify Python\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m \u001b[33;03mseamlessly optimize PyTorch programs, including those using modern Python features.\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config, convert_frame, eval_frame, resume_execution\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackends\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mregistry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m list_backends, lookup_backend, register_backend\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcallback\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m callback_handler, on_compile_end, on_compile_start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Projects for Data Science\\Drug Gi50 Value Prediction\\venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:52\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_C\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mguards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GlobalStateGuard\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_compile_pg\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msymbolic_convert\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TensorifyState\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_guards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compile_context, CompileContext, CompileId, tracing\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_logging\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m structured\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Projects for Data Science\\Drug Gi50 Value Prediction\\venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py:52\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_logging\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TensorifyScalarRestartAnalysis\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_guards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tracing, TracingContext\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexperimental\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msymbolic_shapes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m guard_bool\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Projects for Data Science\\Drug Gi50 Value Prediction\\venv\\Lib\\site-packages\\torch\\_dynamo\\exc.py:41\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_guards\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m counters\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[32m     45\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtypes\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Projects for Data Science\\Drug Gi50 Value Prediction\\venv\\Lib\\site-packages\\torch\\_dynamo\\utils.py:69\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_functorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexperimental\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msymbolic_shapes\u001b[39;00m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_pytree\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytree\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fx\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Projects for Data Science\\Drug Gi50 Value Prediction\\venv\\Lib\\site-packages\\torch\\fx\\experimental\\symbolic_shapes.py:67\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_ordered_set\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OrderedSet\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_python_dispatch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_traceable_wrapper_subclass\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_sympy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     68\u001b[39m     Application,\n\u001b[32m     69\u001b[39m     CeilToInt,\n\u001b[32m     70\u001b[39m     CleanDiv,\n\u001b[32m     71\u001b[39m     FloorDiv,\n\u001b[32m     72\u001b[39m     FloorToInt,\n\u001b[32m     73\u001b[39m     IsNonOverlappingAndDenseIndicator,\n\u001b[32m     74\u001b[39m     Max,\n\u001b[32m     75\u001b[39m     Mod,\n\u001b[32m     76\u001b[39m     PythonMod,\n\u001b[32m     77\u001b[39m )\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_sympy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnumbers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m int_oo\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_sympy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprinters\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CppPrinter, PythonPrinter\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Projects for Data Science\\Drug Gi50 Value Prediction\\venv\\Lib\\site-packages\\torch\\utils\\_sympy\\functions.py:9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Callable, Optional, SupportsFloat, TYPE_CHECKING, TypeVar, Union\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping_extensions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TypeVarTuple, Unpack\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msympy\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msympy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m S\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msympy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sympify\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Projects for Data Science\\Drug Gi50 Value Prediction\\venv\\Lib\\site-packages\\sympy\\__init__.py:74\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlogic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (to_cnf, to_dnf, to_nnf, And, Or, Not, Xor, Nand, Nor,\n\u001b[32m     68\u001b[39m         Implies, Equivalent, ITE, POSform, SOPform, simplify_logic, bool_map,\n\u001b[32m     69\u001b[39m         true, false, satisfiable)\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01massumptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (AppliedPredicate, Predicate, AssumptionsContext,\n\u001b[32m     72\u001b[39m         assuming, Q, ask, register_handler, remove_handler, refine)\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpolys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (Poly, PurePoly, poly_from_expr, parallel_poly_from_expr,\n\u001b[32m     75\u001b[39m         degree, total_degree, degree_list, LC, LM, LT, pdiv, prem, pquo,\n\u001b[32m     76\u001b[39m         pexquo, div, rem, quo, exquo, half_gcdex, gcdex, invert,\n\u001b[32m     77\u001b[39m         subresultants, resultant, discriminant, cofactors, gcd_list, gcd,\n\u001b[32m     78\u001b[39m         lcm_list, lcm, terms_gcd, trunc, monic, content, primitive, compose,\n\u001b[32m     79\u001b[39m         decompose, sturm, gff_list, gff, sqf_norm, sqf_part, sqf_list, sqf,\n\u001b[32m     80\u001b[39m         factor_list, factor, intervals, refine_root, count_roots, all_roots,\n\u001b[32m     81\u001b[39m         real_roots, nroots, ground_roots, nth_power_roots_poly, cancel,\n\u001b[32m     82\u001b[39m         reduced, groebner, is_zero_dimensional, GroebnerBasis, poly,\n\u001b[32m     83\u001b[39m         symmetrize, horner, interpolate, rational_interpolate, viete, together,\n\u001b[32m     84\u001b[39m         BasePolynomialError, ExactQuotientFailed, PolynomialDivisionFailed,\n\u001b[32m     85\u001b[39m         OperationNotSupported, HeuristicGCDFailed, HomomorphismFailed,\n\u001b[32m     86\u001b[39m         IsomorphismFailed, ExtraneousFactors, EvaluationFailed,\n\u001b[32m     87\u001b[39m         RefinementFailed, CoercionFailed, NotInvertible, NotReversible,\n\u001b[32m     88\u001b[39m         NotAlgebraic, DomainError, PolynomialError, UnificationFailed,\n\u001b[32m     89\u001b[39m         GeneratorsError, GeneratorsNeeded, ComputationFailed,\n\u001b[32m     90\u001b[39m         UnivariatePolynomialError, MultivariatePolynomialError,\n\u001b[32m     91\u001b[39m         PolificationFailed, OptionError, FlagError, minpoly,\n\u001b[32m     92\u001b[39m         minimal_polynomial, primitive_element, field_isomorphism,\n\u001b[32m     93\u001b[39m         to_number_field, isolate, round_two, prime_decomp, prime_valuation,\n\u001b[32m     94\u001b[39m         galois_group, itermonomials, Monomial, lex, grlex,\n\u001b[32m     95\u001b[39m         grevlex, ilex, igrlex, igrevlex, CRootOf, rootof, RootOf,\n\u001b[32m     96\u001b[39m         ComplexRootOf, RootSum, roots, Domain, FiniteField, IntegerRing,\n\u001b[32m     97\u001b[39m         RationalField, RealField, ComplexField, PythonFiniteField,\n\u001b[32m     98\u001b[39m         GMPYFiniteField, PythonIntegerRing, GMPYIntegerRing, PythonRational,\n\u001b[32m     99\u001b[39m         GMPYRationalField, AlgebraicField, PolynomialRing, FractionField,\n\u001b[32m    100\u001b[39m         ExpressionDomain, FF_python, FF_gmpy, ZZ_python, ZZ_gmpy, QQ_python,\n\u001b[32m    101\u001b[39m         QQ_gmpy, GF, FF, ZZ, QQ, ZZ_I, QQ_I, RR, CC, EX, EXRAW,\n\u001b[32m    102\u001b[39m         construct_domain, swinnerton_dyer_poly, cyclotomic_poly,\n\u001b[32m    103\u001b[39m         symmetric_poly, random_poly, interpolating_poly, jacobi_poly,\n\u001b[32m    104\u001b[39m         chebyshevt_poly, chebyshevu_poly, hermite_poly, hermite_prob_poly,\n\u001b[32m    105\u001b[39m         legendre_poly, laguerre_poly, apart, apart_list, assemble_partfrac_list,\n\u001b[32m    106\u001b[39m         Options, ring, xring, vring, sring, field, xfield, vfield, sfield)\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mseries\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (Order, O, limit, Limit, gruntz, series, approximants,\n\u001b[32m    109\u001b[39m         residue, EmptySequence, SeqPer, SeqFormula, sequence, SeqAdd, SeqMul,\n\u001b[32m    110\u001b[39m         fourier_series, fps, difference_delta, limit_seq)\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (factorial, factorial2, rf, ff, binomial,\n\u001b[32m    113\u001b[39m         RisingFactorial, FallingFactorial, subfactorial, carmichael,\n\u001b[32m    114\u001b[39m         fibonacci, lucas, motzkin, tribonacci, harmonic, bernoulli, bell, euler,\n\u001b[32m   (...)\u001b[39m\u001b[32m    135\u001b[39m         Znm, elliptic_k, elliptic_f, elliptic_e, elliptic_pi, beta, mathieus,\n\u001b[32m    136\u001b[39m         mathieuc, mathieusprime, mathieucprime, riemann_xi, betainc, betainc_regularized)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Projects for Data Science\\Drug Gi50 Value Prediction\\venv\\Lib\\site-packages\\sympy\\polys\\__init__.py:124\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01morthopolys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (jacobi_poly, chebyshevt_poly, chebyshevu_poly,\n\u001b[32m    119\u001b[39m         hermite_poly, hermite_prob_poly, legendre_poly, laguerre_poly)\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mappellseqs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (bernoulli_poly, bernoulli_c_poly, genocchi_poly,\n\u001b[32m    122\u001b[39m         euler_poly, andre_poly)\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpartfrac\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m apart, apart_list, assemble_partfrac_list\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpolyoptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Options\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ring, xring, vring, sring\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Projects for Data Science\\Drug Gi50 Value Prediction\\venv\\Lib\\site-packages\\sympy\\polys\\partfrac.py:13\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msympy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpolys\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpolytools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parallel_poly_from_expr\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msympy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutilities\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m numbered_symbols, take, xthreaded, public\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;129;43m@xthreaded\u001b[39;49m\n\u001b[32m     14\u001b[39m \u001b[38;5;129;43m@public\u001b[39;49m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43mapart\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;250;43m    \u001b[39;49m\u001b[33;43;03m\"\"\"\u001b[39;49;00m\n\u001b[32m     17\u001b[39m \u001b[33;43;03m    Compute partial fraction decomposition of a rational function.\u001b[39;49;00m\n\u001b[32m     18\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     67\u001b[39m \u001b[33;43;03m    apart_list, assemble_partfrac_list\u001b[39;49;00m\n\u001b[32m     68\u001b[39m \u001b[33;43;03m    \"\"\"\u001b[39;49;00m\n\u001b[32m     69\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallowed_flags\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Projects for Data Science\\Drug Gi50 Value Prediction\\venv\\Lib\\site-packages\\sympy\\utilities\\decorator.py:76\u001b[39m, in \u001b[36mxthreaded\u001b[39m\u001b[34m(func)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mxthreaded\u001b[39m(func):\n\u001b[32m     60\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Apply ``func`` to sub--elements of an object, excluding :class:`~.Add`.\u001b[39;00m\n\u001b[32m     61\u001b[39m \n\u001b[32m     62\u001b[39m \u001b[33;03m    This decorator is intended to make it uniformly possible to apply a\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     74\u001b[39m \n\u001b[32m     75\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mthreaded_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Projects for Data Science\\Drug Gi50 Value Prediction\\venv\\Lib\\site-packages\\sympy\\utilities\\decorator.py:13\u001b[39m, in \u001b[36mthreaded_factory\u001b[39m\u001b[34m(func, use_add)\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"A factory for ``threaded`` decorators. \"\"\"\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msympy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sympify\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msympy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmatrices\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MatrixBase\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msympy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutilities\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01miterables\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m iterable\n\u001b[32m     16\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mthreaded_func\u001b[39m(expr, *args, **kwargs):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Projects for Data Science\\Drug Gi50 Value Prediction\\venv\\Lib\\site-packages\\sympy\\matrices\\__init__.py:22\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01msparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MutableSparseMatrix\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01msparsetools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m banded\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimmutable\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ImmutableDenseMatrix, ImmutableSparseMatrix\n\u001b[32m     24\u001b[39m ImmutableMatrix = ImmutableDenseMatrix\n\u001b[32m     25\u001b[39m SparseMatrix = MutableSparseMatrix\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Projects for Data Science\\Drug Gi50 Value Prediction\\venv\\Lib\\site-packages\\sympy\\matrices\\immutable.py:8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msympy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msympify\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _sympy_converter \u001b[38;5;28;01mas\u001b[39;00m sympify_converter, _sympify\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msympy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmatrices\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdense\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DenseMatrix\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msympy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmatrices\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexpressions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MatrixExpr\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msympy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmatrices\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmatrixbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MatrixBase\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msympy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmatrices\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrepmatrix\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RepMatrix\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Projects for Data Science\\Drug Gi50 Value Prediction\\venv\\Lib\\site-packages\\sympy\\matrices\\expressions\\__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\" A module which handles Matrix Expressions \"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mslice\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MatrixSlice\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mblockmatrix\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BlockMatrix, BlockDiagMatrix, block_collapse, blockcut\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompanion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CompanionMatrix\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Projects for Data Science\\Drug Gi50 Value Prediction\\venv\\Lib\\site-packages\\sympy\\matrices\\expressions\\slice.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msympy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmatrices\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexpressions\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmatexpr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MatrixExpr\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msympy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbasic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Basic\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msympy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcontainers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Tuple\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Projects for Data Science\\Drug Gi50 Value Prediction\\venv\\Lib\\site-packages\\sympy\\matrices\\expressions\\matexpr.py:882\u001b[39m\n\u001b[32m    878\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[32m    879\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ImmutableDenseMatrix([[x]])\n\u001b[32m--> \u001b[39m\u001b[32m882\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmatmul\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MatMul\n\u001b[32m    883\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmatadd\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MatAdd\n\u001b[32m    884\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmatpow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MatPow\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Projects for Data Science\\Drug Gi50 Value Prediction\\venv\\Lib\\site-packages\\sympy\\matrices\\expressions\\matmul.py:15\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msympy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutilities\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sympy_deprecation_warning\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msympy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmatrices\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexpressions\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_shape\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m validate_matmul_integer \u001b[38;5;28;01mas\u001b[39;00m validate\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01minverse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Inverse\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmatexpr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MatrixExpr\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmatpow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MatPow\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Projects for Data Science\\Drug Gi50 Value Prediction\\venv\\Lib\\site-packages\\sympy\\matrices\\expressions\\inverse.py:5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msympy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m S, Basic\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msympy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmatrices\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NonSquareMatrixError\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msympy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmatrices\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexpressions\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmatpow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MatPow\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mInverse\u001b[39;00m(MatPow):\n\u001b[32m      9\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[33;03m    The multiplicative inverse of a matrix expression\u001b[39;00m\n\u001b[32m     11\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     30\u001b[39m \n\u001b[32m     31\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1176\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1138\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1078\u001b[39m, in \u001b[36m_find_spec\u001b[39m\u001b[34m(name, path, target)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1504\u001b[39m, in \u001b[36mfind_spec\u001b[39m\u001b[34m(cls, fullname, path, target)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1476\u001b[39m, in \u001b[36m_get_spec\u001b[39m\u001b[34m(cls, fullname, path, target)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1612\u001b[39m, in \u001b[36mfind_spec\u001b[39m\u001b[34m(self, fullname, target)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:147\u001b[39m, in \u001b[36m_path_stat\u001b[39m\u001b[34m(path)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "study_dir = Path(\"../studies/mlp_study\")\n",
    "study_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "study_db_path = f\"sqlite:///{study_dir / 'mlp_optuna_study.db'}\"\n",
    "study_name = \"mlp_regression_pGI50\"\n",
    "print(f\"Optuna study for MLP will be stored at: {study_db_path}\")\n",
    "\n",
    "pruner = optuna.pruners.MedianPruner(\n",
    "    n_startup_trials=10,  # Run at least these many trials completely before starting to prune\n",
    "    n_warmup_steps=20,    # Don't prune trials until they've completed these many epochs\n",
    "    interval_steps=10     # Check for pruning every these many epochs\n",
    ")\n",
    "\n",
    "# Check if a study with the same name already exists in the database\n",
    "# If it does, load it to resume the optimization.\n",
    "try:\n",
    "    study = optuna.load_study(study_name=study_name, storage=study_db_path)\n",
    "    print(f\"Loaded existing study '{study_name}' from {study_db_path}. Resuming optimization.\")\n",
    "except KeyError:\n",
    "    # If the study does not exist, create a new one\n",
    "    print(f\"Creating new study '{study_name}' at {study_db_path}.\")\n",
    "    study = optuna.create_study(\n",
    "        study_name=study_name,\n",
    "        direction=\"minimize\",\n",
    "        storage=study_db_path,\n",
    "        pruner=pruner\n",
    "    )\n",
    "\n",
    "print(\"\\nStarting Optuna optimization for MLP...\")\n",
    "study.optimize(objective,\n",
    "                   n_trials=50,\n",
    "                   timeout=7200,\n",
    "                   show_progress_bar=True)\n",
    "print(\"\\nOptuna optimization finished for MLP.\")\n",
    "\n",
    "# Print best trial results\n",
    "print(\"\\n--- Best Trial Results for MLP ---\")\n",
    "print(f\"Best trial number: {study.best_trial.number}\")\n",
    "print(f\"Best RMSE (Validation): {study.best_value:.4f}\")\n",
    "print(\"Best hyperparameters:\")\n",
    "for key, value in study.best_params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "if \"final_r2_score\" in study.best_trial.user_attrs:\n",
    "    print(f\"Best R2 Score (Validation): {study.best_trial.user_attrs['final_r2_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b70318-884b-4f20-b1fd-62b22fa1b25b",
   "metadata": {},
   "source": [
    "## 5. Train Final Model\n",
    "This section trains the final MLP model using the best hyperparameters identified by Optuna and saves it for future use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559b991a-66d2-4293-8c8c-03003b975e11",
   "metadata": {},
   "source": [
    "### 5.1. Reinitialize Everything with Best Hyperparams\n",
    "The MLP model is reinitialized with the optimal hyperparameters found during the Optuna study, along with the final training (training and validation data **combined**) and testing data, and their respective DataLoaders. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00252baf-050d-48a5-92d1-aa337cfec049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial parameters (MLP): {'hidden_size': 801, 'lr': 0.00016038661160511867, 'batch_size': 128, 'n_epochs': 195}\n",
      "Best hyperparameters from Optuna: {'hidden_size': 801, 'lr': 0.00016038661160511867, 'batch_size': 128, 'n_epochs': 195}\n",
      "Final model, criterion, optimizer, and DataLoaders initialized with best parameters.\n"
     ]
    }
   ],
   "source": [
    "# Re-load the study to ensure the latest best parameters\n",
    "study_dir = Path(\"../studies/mlp_study\")\n",
    "study_db_path = f\"sqlite:///{study_dir / 'mlp_optuna_study.db'}\"\n",
    "study_name = \"mlp_regression_pGI50\"\n",
    "\n",
    "try:\n",
    "    study = optuna.load_study(study_name=study_name, storage=study_db_path)\n",
    "    print(\"Best trial parameters (MLP):\", study.best_trial.params)\n",
    "    best_params = study.best_trial.params\n",
    "except KeyError:\n",
    "    print(\"Study does not exist. Please make sure that the previous Optuna study cell has been run.\")\n",
    "\n",
    "best_params = study.best_trial.params\n",
    "best_hidden_size = best_params[\"hidden_size\"]\n",
    "best_learning_rate = best_params[\"lr\"]\n",
    "best_batch_size = best_params[\"batch_size\"]\n",
    "best_n_epochs = best_params[\"n_epochs\"]\n",
    "\n",
    "print(f\"Best hyperparameters from Optuna: {best_params}\")\n",
    "\n",
    "# Re-initialize the model with best hyperparameters\n",
    "input_size = X_train_tensor.shape[1]\n",
    "output_size = 1\n",
    "final_mlp_model = MLP(input_size, best_hidden_size, output_size).to(device)\n",
    "\n",
    "# Re-initialize criterion and optimizer\n",
    "final_criterion = nn.MSELoss()\n",
    "final_optimizer = optim.Adam(final_mlp_model.parameters(), lr=best_learning_rate)\n",
    "\n",
    "# Re-create DataLoaders with the best batch size (Training + Validation data COMBINED)\n",
    "X_train_val_tensor = torch.cat((X_train_tensor, X_val_tensor), dim=0)\n",
    "y_train_val_tensor = torch.cat((y_train_tensor, y_val_tensor), dim=0)\n",
    "\n",
    "final_train_val_dataset = TensorDataset(X_train_val_tensor, y_train_val_tensor)\n",
    "final_train_val_loader = DataLoader(final_train_val_dataset, batch_size=best_batch_size, shuffle=True)\n",
    "\n",
    "# Create the FINAL TEST DataLoader\n",
    "final_test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "final_test_loader = DataLoader(final_test_dataset, batch_size=best_batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Final model, criterion, optimizer, and DataLoaders initialized with best parameters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3824aa-b3a6-4209-b467-750f679a0fef",
   "metadata": {},
   "source": [
    "### 5.2. Get Current Git Commit ID\n",
    "The current Git commit ID (hash) is programmatically retrieved. This commit ID will be incorporated into the final model's filename to ensure direct traceability and reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c918ad5-506d-48ae-bff3-8d985261c8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_git_commit_hash():\n",
    "    try:\n",
    "        # Get the short commit hash\n",
    "        commit_hash = subprocess.check_output(['git', 'rev-parse', '--short', 'HEAD']).strip().decode('ascii')\n",
    "        return commit_hash\n",
    "    except (subprocess.CalledProcessError, FileNotFoundError):\n",
    "        return \"unknown_commit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3eaf2e7f-ec98-4bc4-b242-ba2dca3c3760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Git Commit ID: 49ef37f\n"
     ]
    }
   ],
   "source": [
    "# Optionally, see the current commit ID\n",
    "current_commit = get_git_commit_hash()\n",
    "print(f\"Current Git Commit ID: {current_commit}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c629f2-d49e-4e64-be1f-46215e9f7253",
   "metadata": {},
   "source": [
    "### 5.3. Train and Save Model\n",
    "The final MLP model is trained on the combined training and validation datasets and then saved locally with a filename that includes the Git commit ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4925285b-29f4-4f45-856f-066ce800d6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining final MLP model for 195 epochs with best parameters...\n",
      "Associated Git Commit ID for saved model: 5b6c756\n",
      "Epoch 1/195, Train Loss: 10.0220, Eval RMSE on combined data: 0.9285\n",
      "--- New best final model saved at epoch 1 with RMSE: 0.9285 ---\n",
      "Epoch 2/195, Train Loss: 0.6577, Eval RMSE on combined data: 0.6521\n",
      "--- New best final model saved at epoch 2 with RMSE: 0.6521 ---\n",
      "Epoch 3/195, Train Loss: 0.4163, Eval RMSE on combined data: 0.5558\n",
      "--- New best final model saved at epoch 3 with RMSE: 0.5558 ---\n",
      "Epoch 4/195, Train Loss: 0.3185, Eval RMSE on combined data: 0.4916\n",
      "--- New best final model saved at epoch 4 with RMSE: 0.4916 ---\n",
      "Epoch 5/195, Train Loss: 0.2558, Eval RMSE on combined data: 0.4461\n",
      "--- New best final model saved at epoch 5 with RMSE: 0.4461 ---\n",
      "Epoch 6/195, Train Loss: 0.2131, Eval RMSE on combined data: 0.4061\n",
      "--- New best final model saved at epoch 6 with RMSE: 0.4061 ---\n",
      "Epoch 7/195, Train Loss: 0.1824, Eval RMSE on combined data: 0.3762\n",
      "--- New best final model saved at epoch 7 with RMSE: 0.3762 ---\n",
      "Epoch 8/195, Train Loss: 0.1603, Eval RMSE on combined data: 0.3475\n",
      "--- New best final model saved at epoch 8 with RMSE: 0.3475 ---\n",
      "Epoch 9/195, Train Loss: 0.1397, Eval RMSE on combined data: 0.3273\n",
      "--- New best final model saved at epoch 9 with RMSE: 0.3273 ---\n",
      "Epoch 10/195, Train Loss: 0.1251, Eval RMSE on combined data: 0.3123\n",
      "--- New best final model saved at epoch 10 with RMSE: 0.3123 ---\n",
      "Epoch 11/195, Train Loss: 0.1115, Eval RMSE on combined data: 0.3066\n",
      "--- New best final model saved at epoch 11 with RMSE: 0.3066 ---\n",
      "Epoch 12/195, Train Loss: 0.1041, Eval RMSE on combined data: 0.2882\n",
      "--- New best final model saved at epoch 12 with RMSE: 0.2882 ---\n",
      "Epoch 13/195, Train Loss: 0.0971, Eval RMSE on combined data: 0.2763\n",
      "--- New best final model saved at epoch 13 with RMSE: 0.2763 ---\n",
      "Epoch 14/195, Train Loss: 0.0906, Eval RMSE on combined data: 0.2747\n",
      "--- New best final model saved at epoch 14 with RMSE: 0.2747 ---\n",
      "Epoch 15/195, Train Loss: 0.0849, Eval RMSE on combined data: 0.2690\n",
      "--- New best final model saved at epoch 15 with RMSE: 0.2690 ---\n",
      "Epoch 16/195, Train Loss: 0.0824, Eval RMSE on combined data: 0.2696\n",
      "No improvement for 1 epochs. Best RMSE so far: 0.2690\n",
      "Epoch 17/195, Train Loss: 0.0795, Eval RMSE on combined data: 0.2599\n",
      "--- New best final model saved at epoch 17 with RMSE: 0.2599 ---\n",
      "Epoch 18/195, Train Loss: 0.0763, Eval RMSE on combined data: 0.2499\n",
      "--- New best final model saved at epoch 18 with RMSE: 0.2499 ---\n",
      "Epoch 19/195, Train Loss: 0.0731, Eval RMSE on combined data: 0.2599\n",
      "No improvement for 1 epochs. Best RMSE so far: 0.2499\n",
      "Epoch 20/195, Train Loss: 0.0767, Eval RMSE on combined data: 0.2706\n",
      "No improvement for 2 epochs. Best RMSE so far: 0.2499\n",
      "Epoch 21/195, Train Loss: 0.0709, Eval RMSE on combined data: 0.2450\n",
      "--- New best final model saved at epoch 21 with RMSE: 0.2450 ---\n",
      "Epoch 22/195, Train Loss: 0.0758, Eval RMSE on combined data: 0.2324\n",
      "--- New best final model saved at epoch 22 with RMSE: 0.2324 ---\n",
      "Epoch 23/195, Train Loss: 0.0678, Eval RMSE on combined data: 0.2357\n",
      "No improvement for 1 epochs. Best RMSE so far: 0.2324\n",
      "Epoch 24/195, Train Loss: 0.0696, Eval RMSE on combined data: 0.2431\n",
      "No improvement for 2 epochs. Best RMSE so far: 0.2324\n",
      "Epoch 25/195, Train Loss: 0.0638, Eval RMSE on combined data: 0.2382\n",
      "No improvement for 3 epochs. Best RMSE so far: 0.2324\n",
      "Epoch 26/195, Train Loss: 0.0667, Eval RMSE on combined data: 0.2780\n",
      "No improvement for 4 epochs. Best RMSE so far: 0.2324\n",
      "Epoch 27/195, Train Loss: 0.0653, Eval RMSE on combined data: 0.2442\n",
      "No improvement for 5 epochs. Best RMSE so far: 0.2324\n",
      "Epoch 28/195, Train Loss: 0.0619, Eval RMSE on combined data: 0.2255\n",
      "--- New best final model saved at epoch 28 with RMSE: 0.2255 ---\n",
      "Epoch 29/195, Train Loss: 0.0601, Eval RMSE on combined data: 0.2406\n",
      "No improvement for 1 epochs. Best RMSE so far: 0.2255\n",
      "Epoch 30/195, Train Loss: 0.0586, Eval RMSE on combined data: 0.2213\n",
      "--- New best final model saved at epoch 30 with RMSE: 0.2213 ---\n",
      "Epoch 31/195, Train Loss: 0.0576, Eval RMSE on combined data: 0.2296\n",
      "No improvement for 1 epochs. Best RMSE so far: 0.2213\n",
      "Epoch 32/195, Train Loss: 0.0585, Eval RMSE on combined data: 0.2185\n",
      "--- New best final model saved at epoch 32 with RMSE: 0.2185 ---\n",
      "Epoch 33/195, Train Loss: 0.0598, Eval RMSE on combined data: 0.2373\n",
      "No improvement for 1 epochs. Best RMSE so far: 0.2185\n",
      "Epoch 34/195, Train Loss: 0.0599, Eval RMSE on combined data: 0.2322\n",
      "No improvement for 2 epochs. Best RMSE so far: 0.2185\n",
      "Epoch 35/195, Train Loss: 0.0575, Eval RMSE on combined data: 0.2189\n",
      "No improvement for 3 epochs. Best RMSE so far: 0.2185\n",
      "Epoch 36/195, Train Loss: 0.0545, Eval RMSE on combined data: 0.2205\n",
      "No improvement for 4 epochs. Best RMSE so far: 0.2185\n",
      "Epoch 37/195, Train Loss: 0.0594, Eval RMSE on combined data: 0.2459\n",
      "No improvement for 5 epochs. Best RMSE so far: 0.2185\n",
      "Epoch 38/195, Train Loss: 0.0609, Eval RMSE on combined data: 0.2181\n",
      "--- New best final model saved at epoch 38 with RMSE: 0.2181 ---\n",
      "Epoch 39/195, Train Loss: 0.0522, Eval RMSE on combined data: 0.2123\n",
      "--- New best final model saved at epoch 39 with RMSE: 0.2123 ---\n",
      "Epoch 40/195, Train Loss: 0.0541, Eval RMSE on combined data: 0.2101\n",
      "--- New best final model saved at epoch 40 with RMSE: 0.2101 ---\n",
      "Epoch 41/195, Train Loss: 0.0509, Eval RMSE on combined data: 0.2155\n",
      "No improvement for 1 epochs. Best RMSE so far: 0.2101\n",
      "Epoch 42/195, Train Loss: 0.0498, Eval RMSE on combined data: 0.2171\n",
      "No improvement for 2 epochs. Best RMSE so far: 0.2101\n",
      "Epoch 43/195, Train Loss: 0.0499, Eval RMSE on combined data: 0.2100\n",
      "--- New best final model saved at epoch 43 with RMSE: 0.2100 ---\n",
      "Epoch 44/195, Train Loss: 0.0478, Eval RMSE on combined data: 0.2034\n",
      "--- New best final model saved at epoch 44 with RMSE: 0.2034 ---\n",
      "Epoch 45/195, Train Loss: 0.0468, Eval RMSE on combined data: 0.2012\n",
      "--- New best final model saved at epoch 45 with RMSE: 0.2012 ---\n",
      "Epoch 46/195, Train Loss: 0.0482, Eval RMSE on combined data: 0.1953\n",
      "--- New best final model saved at epoch 46 with RMSE: 0.1953 ---\n",
      "Epoch 47/195, Train Loss: 0.0465, Eval RMSE on combined data: 0.2077\n",
      "No improvement for 1 epochs. Best RMSE so far: 0.1953\n",
      "Epoch 48/195, Train Loss: 0.0466, Eval RMSE on combined data: 0.2032\n",
      "No improvement for 2 epochs. Best RMSE so far: 0.1953\n",
      "Epoch 49/195, Train Loss: 0.0471, Eval RMSE on combined data: 0.2096\n",
      "No improvement for 3 epochs. Best RMSE so far: 0.1953\n",
      "Epoch 50/195, Train Loss: 0.0469, Eval RMSE on combined data: 0.1940\n",
      "--- New best final model saved at epoch 50 with RMSE: 0.1940 ---\n",
      "Epoch 51/195, Train Loss: 0.0452, Eval RMSE on combined data: 0.2032\n",
      "No improvement for 1 epochs. Best RMSE so far: 0.1940\n",
      "Epoch 52/195, Train Loss: 0.0458, Eval RMSE on combined data: 0.1974\n",
      "No improvement for 2 epochs. Best RMSE so far: 0.1940\n",
      "Epoch 53/195, Train Loss: 0.0441, Eval RMSE on combined data: 0.1908\n",
      "--- New best final model saved at epoch 53 with RMSE: 0.1908 ---\n",
      "Epoch 54/195, Train Loss: 0.0423, Eval RMSE on combined data: 0.1920\n",
      "No improvement for 1 epochs. Best RMSE so far: 0.1908\n",
      "Epoch 55/195, Train Loss: 0.0440, Eval RMSE on combined data: 0.1992\n",
      "No improvement for 2 epochs. Best RMSE so far: 0.1908\n",
      "Epoch 56/195, Train Loss: 0.0418, Eval RMSE on combined data: 0.1939\n",
      "No improvement for 3 epochs. Best RMSE so far: 0.1908\n",
      "Epoch 57/195, Train Loss: 0.0416, Eval RMSE on combined data: 0.1945\n",
      "No improvement for 4 epochs. Best RMSE so far: 0.1908\n",
      "Epoch 58/195, Train Loss: 0.0433, Eval RMSE on combined data: 0.1845\n",
      "--- New best final model saved at epoch 58 with RMSE: 0.1845 ---\n",
      "Epoch 59/195, Train Loss: 0.0427, Eval RMSE on combined data: 0.1925\n",
      "No improvement for 1 epochs. Best RMSE so far: 0.1845\n",
      "Epoch 60/195, Train Loss: 0.0409, Eval RMSE on combined data: 0.1912\n",
      "No improvement for 2 epochs. Best RMSE so far: 0.1845\n",
      "Epoch 61/195, Train Loss: 0.0402, Eval RMSE on combined data: 0.1860\n",
      "No improvement for 3 epochs. Best RMSE so far: 0.1845\n",
      "Epoch 62/195, Train Loss: 0.0412, Eval RMSE on combined data: 0.1858\n",
      "No improvement for 4 epochs. Best RMSE so far: 0.1845\n",
      "Epoch 63/195, Train Loss: 0.0409, Eval RMSE on combined data: 0.1972\n",
      "No improvement for 5 epochs. Best RMSE so far: 0.1845\n",
      "Epoch 64/195, Train Loss: 0.0430, Eval RMSE on combined data: 0.1923\n",
      "No improvement for 6 epochs. Best RMSE so far: 0.1845\n",
      "Epoch 65/195, Train Loss: 0.0389, Eval RMSE on combined data: 0.1829\n",
      "--- New best final model saved at epoch 65 with RMSE: 0.1829 ---\n",
      "Epoch 66/195, Train Loss: 0.0408, Eval RMSE on combined data: 0.1907\n",
      "No improvement for 1 epochs. Best RMSE so far: 0.1829\n",
      "Epoch 67/195, Train Loss: 0.0408, Eval RMSE on combined data: 0.1854\n",
      "No improvement for 2 epochs. Best RMSE so far: 0.1829\n",
      "Epoch 68/195, Train Loss: 0.0379, Eval RMSE on combined data: 0.1766\n",
      "--- New best final model saved at epoch 68 with RMSE: 0.1766 ---\n",
      "Epoch 69/195, Train Loss: 0.0371, Eval RMSE on combined data: 0.1871\n",
      "No improvement for 1 epochs. Best RMSE so far: 0.1766\n",
      "Epoch 70/195, Train Loss: 0.0391, Eval RMSE on combined data: 0.1798\n",
      "No improvement for 2 epochs. Best RMSE so far: 0.1766\n",
      "Epoch 71/195, Train Loss: 0.0382, Eval RMSE on combined data: 0.1877\n",
      "No improvement for 3 epochs. Best RMSE so far: 0.1766\n",
      "Epoch 72/195, Train Loss: 0.0366, Eval RMSE on combined data: 0.1805\n",
      "No improvement for 4 epochs. Best RMSE so far: 0.1766\n",
      "Epoch 73/195, Train Loss: 0.0375, Eval RMSE on combined data: 0.1829\n",
      "No improvement for 5 epochs. Best RMSE so far: 0.1766\n",
      "Epoch 74/195, Train Loss: 0.0394, Eval RMSE on combined data: 0.1964\n",
      "No improvement for 6 epochs. Best RMSE so far: 0.1766\n",
      "Epoch 75/195, Train Loss: 0.0375, Eval RMSE on combined data: 0.1757\n",
      "--- New best final model saved at epoch 75 with RMSE: 0.1757 ---\n",
      "Epoch 76/195, Train Loss: 0.0364, Eval RMSE on combined data: 0.1747\n",
      "--- New best final model saved at epoch 76 with RMSE: 0.1747 ---\n",
      "Epoch 77/195, Train Loss: 0.0368, Eval RMSE on combined data: 0.1782\n",
      "No improvement for 1 epochs. Best RMSE so far: 0.1747\n",
      "Epoch 78/195, Train Loss: 0.0354, Eval RMSE on combined data: 0.1752\n",
      "No improvement for 2 epochs. Best RMSE so far: 0.1747\n",
      "Epoch 79/195, Train Loss: 0.0339, Eval RMSE on combined data: 0.1686\n",
      "--- New best final model saved at epoch 79 with RMSE: 0.1686 ---\n",
      "Epoch 80/195, Train Loss: 0.0348, Eval RMSE on combined data: 0.1743\n",
      "No improvement for 1 epochs. Best RMSE so far: 0.1686\n",
      "Epoch 81/195, Train Loss: 0.0331, Eval RMSE on combined data: 0.1746\n",
      "No improvement for 2 epochs. Best RMSE so far: 0.1686\n",
      "Epoch 82/195, Train Loss: 0.0347, Eval RMSE on combined data: 0.1734\n",
      "No improvement for 3 epochs. Best RMSE so far: 0.1686\n",
      "Epoch 83/195, Train Loss: 0.0356, Eval RMSE on combined data: 0.1750\n",
      "No improvement for 4 epochs. Best RMSE so far: 0.1686\n",
      "Epoch 84/195, Train Loss: 0.0343, Eval RMSE on combined data: 0.1716\n",
      "No improvement for 5 epochs. Best RMSE so far: 0.1686\n",
      "Epoch 85/195, Train Loss: 0.0345, Eval RMSE on combined data: 0.1768\n",
      "No improvement for 6 epochs. Best RMSE so far: 0.1686\n",
      "Epoch 86/195, Train Loss: 0.0334, Eval RMSE on combined data: 0.1756\n",
      "No improvement for 7 epochs. Best RMSE so far: 0.1686\n",
      "Epoch 87/195, Train Loss: 0.0348, Eval RMSE on combined data: 0.1759\n",
      "No improvement for 8 epochs. Best RMSE so far: 0.1686\n",
      "Epoch 88/195, Train Loss: 0.0336, Eval RMSE on combined data: 0.1715\n",
      "No improvement for 9 epochs. Best RMSE so far: 0.1686\n",
      "Epoch 89/195, Train Loss: 0.0331, Eval RMSE on combined data: 0.1742\n",
      "No improvement for 10 epochs. Best RMSE so far: 0.1686\n",
      "Epoch 90/195, Train Loss: 0.0323, Eval RMSE on combined data: 0.1736\n",
      "No improvement for 11 epochs. Best RMSE so far: 0.1686\n",
      "Epoch 91/195, Train Loss: 0.0318, Eval RMSE on combined data: 0.1627\n",
      "--- New best final model saved at epoch 91 with RMSE: 0.1627 ---\n",
      "Epoch 92/195, Train Loss: 0.0302, Eval RMSE on combined data: 0.1689\n",
      "No improvement for 1 epochs. Best RMSE so far: 0.1627\n",
      "Epoch 93/195, Train Loss: 0.0329, Eval RMSE on combined data: 0.1735\n",
      "No improvement for 2 epochs. Best RMSE so far: 0.1627\n",
      "Epoch 94/195, Train Loss: 0.0342, Eval RMSE on combined data: 0.1763\n",
      "No improvement for 3 epochs. Best RMSE so far: 0.1627\n",
      "Epoch 95/195, Train Loss: 0.0340, Eval RMSE on combined data: 0.1691\n",
      "No improvement for 4 epochs. Best RMSE so far: 0.1627\n",
      "Epoch 96/195, Train Loss: 0.0336, Eval RMSE on combined data: 0.1764\n",
      "No improvement for 5 epochs. Best RMSE so far: 0.1627\n",
      "Epoch 97/195, Train Loss: 0.0323, Eval RMSE on combined data: 0.1703\n",
      "No improvement for 6 epochs. Best RMSE so far: 0.1627\n",
      "Epoch 98/195, Train Loss: 0.0307, Eval RMSE on combined data: 0.1629\n",
      "No improvement for 7 epochs. Best RMSE so far: 0.1627\n",
      "Epoch 99/195, Train Loss: 0.0312, Eval RMSE on combined data: 0.1630\n",
      "No improvement for 8 epochs. Best RMSE so far: 0.1627\n",
      "Epoch 100/195, Train Loss: 0.0306, Eval RMSE on combined data: 0.1645\n",
      "No improvement for 9 epochs. Best RMSE so far: 0.1627\n",
      "Epoch 101/195, Train Loss: 0.0304, Eval RMSE on combined data: 0.1652\n",
      "No improvement for 10 epochs. Best RMSE so far: 0.1627\n",
      "Epoch 102/195, Train Loss: 0.0310, Eval RMSE on combined data: 0.1669\n",
      "No improvement for 11 epochs. Best RMSE so far: 0.1627\n",
      "Epoch 103/195, Train Loss: 0.0312, Eval RMSE on combined data: 0.1636\n",
      "No improvement for 12 epochs. Best RMSE so far: 0.1627\n",
      "Epoch 104/195, Train Loss: 0.0306, Eval RMSE on combined data: 0.1602\n",
      "--- New best final model saved at epoch 104 with RMSE: 0.1602 ---\n",
      "Epoch 105/195, Train Loss: 0.0312, Eval RMSE on combined data: 0.1619\n",
      "No improvement for 1 epochs. Best RMSE so far: 0.1602\n",
      "Epoch 106/195, Train Loss: 0.0295, Eval RMSE on combined data: 0.1585\n",
      "--- New best final model saved at epoch 106 with RMSE: 0.1585 ---\n",
      "Epoch 107/195, Train Loss: 0.0294, Eval RMSE on combined data: 0.1608\n",
      "No improvement for 1 epochs. Best RMSE so far: 0.1585\n",
      "Epoch 108/195, Train Loss: 0.0299, Eval RMSE on combined data: 0.1595\n",
      "No improvement for 2 epochs. Best RMSE so far: 0.1585\n",
      "Epoch 109/195, Train Loss: 0.0304, Eval RMSE on combined data: 0.1593\n",
      "No improvement for 3 epochs. Best RMSE so far: 0.1585\n",
      "Epoch 110/195, Train Loss: 0.0308, Eval RMSE on combined data: 0.1654\n",
      "No improvement for 4 epochs. Best RMSE so far: 0.1585\n",
      "Epoch 111/195, Train Loss: 0.0302, Eval RMSE on combined data: 0.1607\n",
      "No improvement for 5 epochs. Best RMSE so far: 0.1585\n",
      "Epoch 112/195, Train Loss: 0.0308, Eval RMSE on combined data: 0.1624\n",
      "No improvement for 6 epochs. Best RMSE so far: 0.1585\n",
      "Epoch 113/195, Train Loss: 0.0299, Eval RMSE on combined data: 0.1567\n",
      "--- New best final model saved at epoch 113 with RMSE: 0.1567 ---\n",
      "Epoch 114/195, Train Loss: 0.0284, Eval RMSE on combined data: 0.1615\n",
      "No improvement for 1 epochs. Best RMSE so far: 0.1567\n",
      "Epoch 115/195, Train Loss: 0.0283, Eval RMSE on combined data: 0.1578\n",
      "No improvement for 2 epochs. Best RMSE so far: 0.1567\n",
      "Epoch 116/195, Train Loss: 0.0291, Eval RMSE on combined data: 0.1599\n",
      "No improvement for 3 epochs. Best RMSE so far: 0.1567\n",
      "Epoch 117/195, Train Loss: 0.0284, Eval RMSE on combined data: 0.1589\n",
      "No improvement for 4 epochs. Best RMSE so far: 0.1567\n",
      "Epoch 118/195, Train Loss: 0.0286, Eval RMSE on combined data: 0.1618\n",
      "No improvement for 5 epochs. Best RMSE so far: 0.1567\n",
      "Epoch 119/195, Train Loss: 0.0292, Eval RMSE on combined data: 0.1588\n",
      "No improvement for 6 epochs. Best RMSE so far: 0.1567\n",
      "Epoch 120/195, Train Loss: 0.0290, Eval RMSE on combined data: 0.1605\n",
      "No improvement for 7 epochs. Best RMSE so far: 0.1567\n",
      "Epoch 121/195, Train Loss: 0.0284, Eval RMSE on combined data: 0.1601\n",
      "No improvement for 8 epochs. Best RMSE so far: 0.1567\n",
      "Epoch 122/195, Train Loss: 0.0284, Eval RMSE on combined data: 0.1541\n",
      "--- New best final model saved at epoch 122 with RMSE: 0.1541 ---\n",
      "Epoch 123/195, Train Loss: 0.0283, Eval RMSE on combined data: 0.1547\n",
      "No improvement for 1 epochs. Best RMSE so far: 0.1541\n",
      "Epoch 124/195, Train Loss: 0.0286, Eval RMSE on combined data: 0.1563\n",
      "No improvement for 2 epochs. Best RMSE so far: 0.1541\n",
      "Epoch 125/195, Train Loss: 0.0292, Eval RMSE on combined data: 0.1569\n",
      "No improvement for 3 epochs. Best RMSE so far: 0.1541\n",
      "Epoch 126/195, Train Loss: 0.0287, Eval RMSE on combined data: 0.1587\n",
      "No improvement for 4 epochs. Best RMSE so far: 0.1541\n",
      "Epoch 127/195, Train Loss: 0.0279, Eval RMSE on combined data: 0.1526\n",
      "--- New best final model saved at epoch 127 with RMSE: 0.1526 ---\n",
      "Epoch 128/195, Train Loss: 0.0268, Eval RMSE on combined data: 0.1523\n",
      "--- New best final model saved at epoch 128 with RMSE: 0.1523 ---\n",
      "Epoch 129/195, Train Loss: 0.0278, Eval RMSE on combined data: 0.1551\n",
      "No improvement for 1 epochs. Best RMSE so far: 0.1523\n",
      "Epoch 130/195, Train Loss: 0.0272, Eval RMSE on combined data: 0.1525\n",
      "No improvement for 2 epochs. Best RMSE so far: 0.1523\n",
      "Epoch 131/195, Train Loss: 0.0261, Eval RMSE on combined data: 0.1529\n",
      "No improvement for 3 epochs. Best RMSE so far: 0.1523\n",
      "Epoch 132/195, Train Loss: 0.0265, Eval RMSE on combined data: 0.1537\n",
      "No improvement for 4 epochs. Best RMSE so far: 0.1523\n",
      "Epoch 133/195, Train Loss: 0.0258, Eval RMSE on combined data: 0.1495\n",
      "--- New best final model saved at epoch 133 with RMSE: 0.1495 ---\n",
      "Epoch 134/195, Train Loss: 0.0270, Eval RMSE on combined data: 0.1545\n",
      "No improvement for 1 epochs. Best RMSE so far: 0.1495\n",
      "Epoch 135/195, Train Loss: 0.0274, Eval RMSE on combined data: 0.1554\n",
      "No improvement for 2 epochs. Best RMSE so far: 0.1495\n",
      "Epoch 136/195, Train Loss: 0.0272, Eval RMSE on combined data: 0.1499\n",
      "No improvement for 3 epochs. Best RMSE so far: 0.1495\n",
      "Epoch 137/195, Train Loss: 0.0265, Eval RMSE on combined data: 0.1499\n",
      "No improvement for 4 epochs. Best RMSE so far: 0.1495\n",
      "Epoch 138/195, Train Loss: 0.0262, Eval RMSE on combined data: 0.1534\n",
      "No improvement for 5 epochs. Best RMSE so far: 0.1495\n",
      "Epoch 139/195, Train Loss: 0.0264, Eval RMSE on combined data: 0.1521\n",
      "No improvement for 6 epochs. Best RMSE so far: 0.1495\n",
      "Epoch 140/195, Train Loss: 0.0258, Eval RMSE on combined data: 0.1491\n",
      "--- New best final model saved at epoch 140 with RMSE: 0.1491 ---\n",
      "Epoch 141/195, Train Loss: 0.0256, Eval RMSE on combined data: 0.1553\n",
      "No improvement for 1 epochs. Best RMSE so far: 0.1491\n",
      "Epoch 142/195, Train Loss: 0.0272, Eval RMSE on combined data: 0.1554\n",
      "No improvement for 2 epochs. Best RMSE so far: 0.1491\n",
      "Epoch 143/195, Train Loss: 0.0263, Eval RMSE on combined data: 0.1569\n",
      "No improvement for 3 epochs. Best RMSE so far: 0.1491\n",
      "Epoch 144/195, Train Loss: 0.0260, Eval RMSE on combined data: 0.1508\n",
      "No improvement for 4 epochs. Best RMSE so far: 0.1491\n",
      "Epoch 145/195, Train Loss: 0.0255, Eval RMSE on combined data: 0.1535\n",
      "No improvement for 5 epochs. Best RMSE so far: 0.1491\n",
      "Epoch 146/195, Train Loss: 0.0255, Eval RMSE on combined data: 0.1494\n",
      "No improvement for 6 epochs. Best RMSE so far: 0.1491\n",
      "Epoch 147/195, Train Loss: 0.0254, Eval RMSE on combined data: 0.1521\n",
      "No improvement for 7 epochs. Best RMSE so far: 0.1491\n",
      "Epoch 148/195, Train Loss: 0.0257, Eval RMSE on combined data: 0.1460\n",
      "--- New best final model saved at epoch 148 with RMSE: 0.1460 ---\n",
      "Epoch 149/195, Train Loss: 0.0266, Eval RMSE on combined data: 0.1503\n",
      "No improvement for 1 epochs. Best RMSE so far: 0.1460\n",
      "Epoch 150/195, Train Loss: 0.0256, Eval RMSE on combined data: 0.1544\n",
      "No improvement for 2 epochs. Best RMSE so far: 0.1460\n",
      "Epoch 151/195, Train Loss: 0.0254, Eval RMSE on combined data: 0.1479\n",
      "No improvement for 3 epochs. Best RMSE so far: 0.1460\n",
      "Epoch 152/195, Train Loss: 0.0259, Eval RMSE on combined data: 0.1501\n",
      "No improvement for 4 epochs. Best RMSE so far: 0.1460\n",
      "Epoch 153/195, Train Loss: 0.0258, Eval RMSE on combined data: 0.1574\n",
      "No improvement for 5 epochs. Best RMSE so far: 0.1460\n",
      "Epoch 154/195, Train Loss: 0.0270, Eval RMSE on combined data: 0.1470\n",
      "No improvement for 6 epochs. Best RMSE so far: 0.1460\n",
      "Epoch 155/195, Train Loss: 0.0255, Eval RMSE on combined data: 0.1428\n",
      "--- New best final model saved at epoch 155 with RMSE: 0.1428 ---\n",
      "Epoch 156/195, Train Loss: 0.0261, Eval RMSE on combined data: 0.1470\n",
      "No improvement for 1 epochs. Best RMSE so far: 0.1428\n",
      "Epoch 157/195, Train Loss: 0.0250, Eval RMSE on combined data: 0.1464\n",
      "No improvement for 2 epochs. Best RMSE so far: 0.1428\n",
      "Epoch 158/195, Train Loss: 0.0252, Eval RMSE on combined data: 0.1476\n",
      "No improvement for 3 epochs. Best RMSE so far: 0.1428\n",
      "Epoch 159/195, Train Loss: 0.0245, Eval RMSE on combined data: 0.1467\n",
      "No improvement for 4 epochs. Best RMSE so far: 0.1428\n",
      "Epoch 160/195, Train Loss: 0.0251, Eval RMSE on combined data: 0.1498\n",
      "No improvement for 5 epochs. Best RMSE so far: 0.1428\n",
      "Epoch 161/195, Train Loss: 0.0246, Eval RMSE on combined data: 0.1483\n",
      "No improvement for 6 epochs. Best RMSE so far: 0.1428\n",
      "Epoch 162/195, Train Loss: 0.0237, Eval RMSE on combined data: 0.1496\n",
      "No improvement for 7 epochs. Best RMSE so far: 0.1428\n",
      "Epoch 163/195, Train Loss: 0.0243, Eval RMSE on combined data: 0.1463\n",
      "No improvement for 8 epochs. Best RMSE so far: 0.1428\n",
      "Epoch 164/195, Train Loss: 0.0241, Eval RMSE on combined data: 0.1463\n",
      "No improvement for 9 epochs. Best RMSE so far: 0.1428\n",
      "Epoch 165/195, Train Loss: 0.0242, Eval RMSE on combined data: 0.1454\n",
      "No improvement for 10 epochs. Best RMSE so far: 0.1428\n",
      "Epoch 166/195, Train Loss: 0.0244, Eval RMSE on combined data: 0.1425\n",
      "--- New best final model saved at epoch 166 with RMSE: 0.1425 ---\n",
      "Epoch 167/195, Train Loss: 0.0240, Eval RMSE on combined data: 0.1467\n",
      "No improvement for 1 epochs. Best RMSE so far: 0.1425\n",
      "Epoch 168/195, Train Loss: 0.0245, Eval RMSE on combined data: 0.1485\n",
      "No improvement for 2 epochs. Best RMSE so far: 0.1425\n",
      "Epoch 169/195, Train Loss: 0.0254, Eval RMSE on combined data: 0.1452\n",
      "No improvement for 3 epochs. Best RMSE so far: 0.1425\n",
      "Epoch 170/195, Train Loss: 0.0239, Eval RMSE on combined data: 0.1434\n",
      "No improvement for 4 epochs. Best RMSE so far: 0.1425\n",
      "Epoch 171/195, Train Loss: 0.0236, Eval RMSE on combined data: 0.1440\n",
      "No improvement for 5 epochs. Best RMSE so far: 0.1425\n",
      "Epoch 172/195, Train Loss: 0.0234, Eval RMSE on combined data: 0.1430\n",
      "No improvement for 6 epochs. Best RMSE so far: 0.1425\n",
      "Epoch 173/195, Train Loss: 0.0252, Eval RMSE on combined data: 0.1441\n",
      "No improvement for 7 epochs. Best RMSE so far: 0.1425\n",
      "Epoch 174/195, Train Loss: 0.0237, Eval RMSE on combined data: 0.1401\n",
      "--- New best final model saved at epoch 174 with RMSE: 0.1401 ---\n",
      "Epoch 175/195, Train Loss: 0.0238, Eval RMSE on combined data: 0.1478\n",
      "No improvement for 1 epochs. Best RMSE so far: 0.1401\n",
      "Epoch 176/195, Train Loss: 0.0232, Eval RMSE on combined data: 0.1461\n",
      "No improvement for 2 epochs. Best RMSE so far: 0.1401\n",
      "Epoch 177/195, Train Loss: 0.0239, Eval RMSE on combined data: 0.1400\n",
      "--- New best final model saved at epoch 177 with RMSE: 0.1400 ---\n",
      "Epoch 178/195, Train Loss: 0.0225, Eval RMSE on combined data: 0.1430\n",
      "No improvement for 1 epochs. Best RMSE so far: 0.1400\n",
      "Epoch 179/195, Train Loss: 0.0227, Eval RMSE on combined data: 0.1449\n",
      "No improvement for 2 epochs. Best RMSE so far: 0.1400\n",
      "Epoch 180/195, Train Loss: 0.0237, Eval RMSE on combined data: 0.1453\n",
      "No improvement for 3 epochs. Best RMSE so far: 0.1400\n",
      "Epoch 181/195, Train Loss: 0.0229, Eval RMSE on combined data: 0.1492\n",
      "No improvement for 4 epochs. Best RMSE so far: 0.1400\n",
      "Epoch 182/195, Train Loss: 0.0243, Eval RMSE on combined data: 0.1402\n",
      "No improvement for 5 epochs. Best RMSE so far: 0.1400\n",
      "Epoch 183/195, Train Loss: 0.0232, Eval RMSE on combined data: 0.1415\n",
      "No improvement for 6 epochs. Best RMSE so far: 0.1400\n",
      "Epoch 184/195, Train Loss: 0.0232, Eval RMSE on combined data: 0.1446\n",
      "No improvement for 7 epochs. Best RMSE so far: 0.1400\n",
      "Epoch 185/195, Train Loss: 0.0232, Eval RMSE on combined data: 0.1410\n",
      "No improvement for 8 epochs. Best RMSE so far: 0.1400\n",
      "Epoch 186/195, Train Loss: 0.0239, Eval RMSE on combined data: 0.1529\n",
      "No improvement for 9 epochs. Best RMSE so far: 0.1400\n",
      "Epoch 187/195, Train Loss: 0.0246, Eval RMSE on combined data: 0.1409\n",
      "No improvement for 10 epochs. Best RMSE so far: 0.1400\n",
      "Epoch 188/195, Train Loss: 0.0231, Eval RMSE on combined data: 0.1387\n",
      "--- New best final model saved at epoch 188 with RMSE: 0.1387 ---\n",
      "Epoch 189/195, Train Loss: 0.0232, Eval RMSE on combined data: 0.1408\n",
      "No improvement for 1 epochs. Best RMSE so far: 0.1387\n",
      "Epoch 190/195, Train Loss: 0.0225, Eval RMSE on combined data: 0.1416\n",
      "No improvement for 2 epochs. Best RMSE so far: 0.1387\n",
      "Epoch 191/195, Train Loss: 0.0230, Eval RMSE on combined data: 0.1430\n",
      "No improvement for 3 epochs. Best RMSE so far: 0.1387\n",
      "Epoch 192/195, Train Loss: 0.0234, Eval RMSE on combined data: 0.1411\n",
      "No improvement for 4 epochs. Best RMSE so far: 0.1387\n",
      "Epoch 193/195, Train Loss: 0.0232, Eval RMSE on combined data: 0.1487\n",
      "No improvement for 5 epochs. Best RMSE so far: 0.1387\n",
      "Epoch 194/195, Train Loss: 0.0218, Eval RMSE on combined data: 0.1428\n",
      "No improvement for 6 epochs. Best RMSE so far: 0.1387\n",
      "Epoch 195/195, Train Loss: 0.0232, Eval RMSE on combined data: 0.1443\n",
      "No improvement for 7 epochs. Best RMSE so far: 0.1387\n",
      "Final model training complete.\n"
     ]
    }
   ],
   "source": [
    "best_final_val_rmse = float('inf')\n",
    "patience_counter_final = 0\n",
    "final_patience = 50\n",
    "\n",
    "current_commit_hash = get_git_commit_hash()\n",
    "model_filename = f\"final_best_mlp_model_{current_commit_hash}.pt\" # Pre-define filename\n",
    "\n",
    "print(f\"Retraining final MLP model for {best_n_epochs} epochs with best parameters...\")\n",
    "print(f\"Associated Git Commit ID for saved model: {current_commit_hash}\")\n",
    "\n",
    "for epoch in range(best_n_epochs):\n",
    "    # Training\n",
    "    final_mlp_model.train()\n",
    "    total_train_loss = 0\n",
    "    num_train_batches = 0\n",
    "    for batch_x, batch_y in final_train_val_loader:\n",
    "        # Move data to device\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "        \n",
    "        final_optimizer.zero_grad()\n",
    "        outputs = final_mlp_model(batch_x)\n",
    "        loss = final_criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        final_optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        num_train_batches += 1\n",
    "\n",
    "    avg_train_loss = total_train_loss / num_train_batches\n",
    "\n",
    "    # Evaluation\n",
    "    final_mlp_model.eval()\n",
    "    val_predictions = []\n",
    "    val_targets = []\n",
    "    with torch.no_grad():\n",
    "        for batch_x_eval, batch_y_eval in final_train_val_loader:\n",
    "            batch_x_eval = batch_x_eval.to(device)\n",
    "            batch_y_eval = batch_y_eval.to(device)\n",
    "            \n",
    "            val_outputs = final_mlp_model(batch_x_eval)\n",
    "            val_predictions.extend(val_outputs.cpu().numpy().flatten())\n",
    "            val_targets.extend(batch_y_eval.cpu().numpy().flatten())\n",
    "\n",
    "    current_val_rmse = np.sqrt(mean_squared_error(val_targets, val_predictions))\n",
    "    print(f\"Epoch {epoch+1}/{best_n_epochs}, Train Loss: {avg_train_loss:.4f}, Eval RMSE on combined data: {current_val_rmse:.4f}\")\n",
    "\n",
    "    # Dynamic Best Model Saving & Early Stopping\n",
    "    if current_val_rmse < best_final_val_rmse:\n",
    "        best_final_val_rmse = current_val_rmse\n",
    "        torch.save(final_mlp_model.state_dict(), mlp_models_base_dir / model_filename) # Save the model state\n",
    "        patience_counter_final = 0 # Reset patience counter if performance improved\n",
    "        print(f\"--- New best final model saved at epoch {epoch+1} with RMSE: {current_val_rmse:.4f} ---\")\n",
    "    else:\n",
    "        patience_counter_final += 1 # Increment patience counter if no improvement\n",
    "        print(f\"No improvement for {patience_counter_final} epochs. Best RMSE so far: {best_final_val_rmse:.4f}\")\n",
    "\n",
    "    if patience_counter_final >= final_patience:\n",
    "        print(f\"Early stopping triggered at epoch {epoch+1}.\")\n",
    "        break\n",
    "\n",
    "print(\"Final model training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75fe20e-5de7-46c7-ab2b-2ffb51e2768a",
   "metadata": {},
   "source": [
    "## 6. Evaluate Model\n",
    "This section performs a final, unbiased evaluation of the trained MLP model's performance on the previously unseen test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c684fe3e-88a0-4b8f-b021-11604d562405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading best saved model from 'final_best_mlp_model_5b6c756.pt' for final test evaluation...\n",
      "\n",
      "Starting final evaluation on test set...\n",
      "Final Model Test RMSE: 0.6408\n",
      "Final Model Test R2: 0.5716\n"
     ]
    }
   ],
   "source": [
    "# Load the best state dict model\n",
    "print(f\"Loading best saved model from '{model_filename}' for final test evaluation...\")\n",
    "path_to_saved_model = mlp_models_base_dir / model_filename\n",
    "loaded_model_state_dict = torch.load(path_to_saved_model)\n",
    "final_mlp_model.load_state_dict(loaded_model_state_dict)\n",
    "final_mlp_model.eval() # Set to evaluation mode for final test\n",
    "\n",
    "print(\"\\nStarting final evaluation on test set...\")\n",
    "test_predictions = []\n",
    "test_targets = []\n",
    "with torch.no_grad():\n",
    "    for batch_x_test, batch_y_test in final_test_loader:\n",
    "        batch_x_test = batch_x_test.to(device)\n",
    "        batch_y_test = batch_y_test.to(device)\n",
    "\n",
    "        test_outputs = final_mlp_model(batch_x_test)\n",
    "        test_predictions.extend(test_outputs.cpu().numpy().flatten())\n",
    "        test_targets.extend(batch_y_test.cpu().numpy().flatten())\n",
    "\n",
    "final_test_rmse = np.sqrt(mean_squared_error(test_targets, test_predictions))\n",
    "final_test_r2 = r2_score(test_targets, test_predictions)\n",
    "\n",
    "print(f\"Final Model Test RMSE: {final_test_rmse:.4f}\")\n",
    "print(f\"Final Model Test R2: {final_test_r2:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
